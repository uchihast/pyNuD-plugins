# loc_afm.py (å®Œå…¨ç‰ˆ)
# loc_afm.py (å®Œå…¨ç‰ˆ)
# loc_afm.py (ASDä¿å­˜æ©Ÿèƒ½ã«å¯¾å¿œã—ãŸæœ€çµ‚å®Œæˆç‰ˆ)

import sys
import time
import os # <<< osãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import numpy as np
from PyQt5 import QtWidgets, QtCore, QtGui
from scipy.ndimage import maximum_filter, gaussian_filter, zoom, rotate, shift
import cv2
import tifffile

# â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘fileioã‹ã‚‰SaveASDã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ â–¼â–¼â–¼
from fileio import SaveASD
from helperFunctions import get_z_unit

try:
    import globalvals as gv
except ImportError:
    class GVDummy: pass
    gv = GVDummy()

try:
    import pyvista as pv
    from pyvistaqt import QtInteractor
    PYVISTA_AVAILABLE = True
except ImportError as e:
    PYVISTA_AVAILABLE = False
    PV_IMPORT_ERROR = str(e)
else:
    PV_IMPORT_ERROR = None

from skimage.registration import phase_cross_correlation

PLUGIN_NAME = "L-AFM Analysis"

HELP_HTML_EN = """
<h1>L-AFM Analysis (Localization AFM)</h1>

<h2>Overview</h2>
<p>Localization Atomic Force Microscopy (L-AFM) analysis is a technique to construct a "super-resolution image" that surpasses the resolution of the original image. It works by detecting the precise locations of numerous individual molecules' or structures' brightness peaks over time from an AFM time-series image (movie) and reconstructing them onto a high-resolution grid. This panel allows you to perform the series of processes from peak detection to image reconstruction step-by-step.</p>

<h2>Access</h2>
<ul>
    <li><strong>Plugin menu:</strong> Load Plugin... â†’ select <code>plugins/LAFMAnalysis.py</code>, then Plugin â†’ L-AFM Analysis</li>
</ul>

<h2>Overview of Processing Steps</h2>
<p>L-AFM analysis consists of three main steps. Please execute the buttons for each step in order.</p>
<div class="step">
    <strong>Step 1: Preprocessing 1 (Peak Detection)</strong><br>
    Scans each frame of the AFM movie to detect bright spots (peaks) based on set criteria.
</div>
<div class="step">
    <strong>Step 2: Preprocessing 2 (Reconstruction into Space)</strong><br>
    Plots the coordinates of all peaks detected in Step 1 onto a high-resolution 2D grid or into a 3D voxel space.
</div>
<div class="step">
    <strong>Step 3: Make LAFM Image (Super-Resolution Image Generation)</strong><br>
    Applies a Gaussian blur to the pointillistic data created in Step 2 to finish it into a smooth super-resolution image.
</div>

<h2>New Features: Automatic Z-Range Settings</h2>
<p>The L-AFM panel now includes intelligent Z-range optimization features to improve analysis accuracy and user experience.</p>

<h3>Auto Z-Range Button</h3>
<div class="feature-box">
    <h4>Statistical Z-Range Calculation</h4>
    <ul>
        <li><strong>Automatic Calculation:</strong> Analyzes the loaded image stack to determine optimal Z_min and Z_max values based on data statistics.</li>
        <li><strong>Noise Level Consideration:</strong> Estimates noise floor and baseline to set appropriate thresholds.</li>
        <li><strong>Data Coverage:</strong> Ensures the calculated range covers an appropriate percentage of the data points.</li>
        <li><strong>Physical Validity:</strong> Applies minimum thresholds (10 pm) and checks for logical consistency.</li>
    </ul>
</div>

<h3>Sample Type Selection</h3>
<div class="feature-box">
    <h4>Predefined Settings for Different Sample Types</h4>
    <ul>
        <li><strong>General:</strong> Default settings for general purpose analysis (Z_min: 0.1 nm, Z_max: 10.0 nm)</li>
        <li><strong>Proteins:</strong> Optimized for single proteins to large complexes (Z_min: 0.1 nm, Z_max: 10.0 nm)</li>
        <li><strong>DNA/RNA:</strong> Suitable for nucleic acid molecules (Z_min: 0.05 nm, Z_max: 3.0 nm)</li>
        <li><strong>Cells:</strong> For cellular structures and organelles (Z_min: 1.0 nm, Z_max: 100.0 nm)</li>
        <li><strong>Crystals:</strong> For crystal surfaces and defects (Z_min: 0.01 nm, Z_max: 50.0 nm)</li>
        <li><strong>Nanoparticles:</strong> For nanoparticles and aggregates (Z_min: 0.5 nm, Z_max: 20.0 nm)</li>
    </ul>
</div>

<h3>Usage Instructions</h3>
<ol>
    <li><strong>Data Loading:</strong> When image data is loaded, Z-range values are automatically calculated and set.</li>
    <li><strong>Manual Adjustment:</strong> Click the "Auto Z-Range" button to recalculate based on current data.</li>
    <li><strong>Sample Type Selection:</strong> Choose the appropriate sample type from the dropdown to apply recommended settings.</li>
    <li><strong>Range Display:</strong> The current Z-range is displayed next to the button for easy reference.</li>
</ol>

<h2>Difference Between Preprocessing 1 and 2</h2>
<p>These two steps play completely different roles in L-AFM analysis: "<strong>detection</strong>" and "<strong>drawing</strong>."</p>
<div class="feature-box">
    <h4>Preprocessing 1: Peak Search and Detection</h4>
    <ul>
        <li><strong>Input:</strong> The AFM time-series image stack (raw pixel data).</li>
        <li><strong>Process:</strong> Scans each frame and lists the <strong>coordinate information</strong> of "where molecules existed."</li>
        <li><strong>Output:</strong> A list of all detected peaks' coordinates, intensities, frame numbers, etc. (like an address book).</li>
        <li><strong>In short:</strong> It's the process of <strong>creating a "molecule address book" from the images.</strong></li>
    </ul>
</div>
<div class="feature-box">
    <h4>Preprocessing 2: Reconstruction from Coordinate Data to Image</h4>
    <ul>
        <li><strong>Input:</strong> The peak coordinate list output by Preprocessing 1. <strong>(This step does not look at the original images at all.)</strong></li>
        <li><strong>Process:</strong> Prepares a new high-resolution canvas and plots (votes for) points at the locations from the input coordinate list.</li>
        <li><strong>Output:</strong> Pointillistic data representing the density of peak presences.</li>
        <li><strong>In short:</strong> It's the process of <strong>creating a "distribution map" based on the "molecule address book."</strong></li>
    </ul>
</div>

<h2>Parameter Groups and Settings</h2>

<h3>Peak Filtering Group</h3>
<div class="feature-box">
    <h4>Filter Mode</h4>
    <ul>
        <li><strong>Absolute Height (nm):</strong> Filters peaks based on their absolute height values in nanometers.</li>
        <li><strong>Statistics (Mean + N x Std Dev):</strong> Filters peaks based on statistical criteria using mean and standard deviation.</li>
    </ul>

    <h4>Z-Range Settings (New Feature)</h4>
    <ul>
        <li><strong>Auto Z-Range Button:</strong> Automatically calculates optimal Z_min and Z_max values from the loaded image data.</li>
        <li><strong>Z_min (nm):</strong> Minimum height threshold for peak detection.</li>
        <li><strong>Z_max (nm):</strong> Maximum height threshold for peak detection.</li>
        <li><strong>Range Display:</strong> Shows the current Z-range span for easy reference.</li>
    </ul>

    <h4>Sample Type Selection (New Feature)</h4>
    <ul>
        <li><strong>General:</strong> Default settings for general purpose analysis.</li>
        <li><strong>Proteins:</strong> Optimized for protein analysis.</li>
        <li><strong>DNA/RNA:</strong> Suitable for nucleic acid molecules.</li>
        <li><strong>Cells:</strong> For cellular structures and organelles.</li>
        <li><strong>Crystals:</strong> For crystal surfaces and defects.</li>
        <li><strong>Nanoparticles:</strong> For nanoparticles and aggregates.</li>
    </ul>

    <h4>N Factor</h4>
    <ul>
        <li><strong>Purpose:</strong> Multiplier for standard deviation in statistical filtering mode.</li>
        <li><strong>Auto-calculation:</strong> Automatically calculated from the first frame when data is loaded.</li>
    </ul>
</div>

<h2>Deciding Which Step to Rerun After Changing Parameters</h2>
<p>Based on the differences above, the step you need to redo depends on whether the changed parameter affects "detection" or "drawing."</p>

<h3>Parameters Requiring Rerun from Preprocessing 1</h3>
<p>If you change the <strong>"peak detection conditions"</strong> themselves, you need to start over from the first step.</p>
<ul>
    <li>All parameters in the <b>Drift Correction</b> group</li>
    <li>All parameters in the <b>Peak Filtering</b> group</li>
    <li>All parameters in the <b>Local Maxima</b> group</li>
    <li>"Enable Subpixel Localization" and "Scale" in the <b>Subpixel Localization</b> group</li>
</ul>
<h3>Parameters Allowing Rerun from Preprocessing 2</h3>
<p>If you only change the conditions for <strong>"how to draw the already detected peaks,"</strong> you can skip the time-consuming peak detection.</p>
<ul>
    <li><b>Mode</b> (switching between "2D" â‡” "3D")</li>
    <li>"XY Resolution" and "Z Resolution" in the <b>Subpixel Localization</b> group</li>
    <li>The "During Reconstruction (Prep 2)" setting in the <b>Symmetric Averaging</b> group</li>
</ul>

<h3>Parameters Allowing Rerun from Make LAFM Image</h3>
<p>If you only change <strong>"how to finish the reconstructed image,"</strong> you can start from this fastest step.</p>
<ul>
    <li>All parameters in the <b>Gaussian Blur</b> group</li>
    <li>The "On Final LAFM Image" setting in the <b>Symmetric Averaging</b> group</li>
</ul>

<h2>Practical Workflow (Flowchart)</h2>
<p>Below is a flowchart of a practical analysis workflow incorporating the branching conditions described above.</p>
<pre><code>
graph TD
    subgraph Initial Setup
        A[Open L-AFM Panel] --> B{Set Parameters};
    end

    subgraph Step 1: Peak Detection
        B --> C[1. Execute Preprocessing 1];
        C --> D{Are peak detection results valid?<br>(Check count and preview image)};
        D -- No --> E[<b>Reconfigure P1-related parameters</b><br>- Drift Correction<br>- Peak Filtering<br>- Local Maxima<br>- Subpixel (Enable/Scale)];
        E --> C;
    end

    subgraph Step 2: Reconstruction
        D -- Yes --> F[2. Execute Preprocessing 2];
        F --> G{Are reconstruction results valid?<br>(Check image density and distribution)};
        G -- No --> H[<b>Reconfigure P2-related parameters</b><br>- Mode (2D/3D)<br>- Subpixel Resolution<br>- Symmetric Avg (Prep 2)];
        H --> F;
    end

    subgraph Step 3: Image Generation and Saving
        G -- Yes --> I[3. Execute Make LAFM Image];
        I --> J{Is the final image satisfactory?<br>(Check smoothness and appearance)};
        J -- No --> K[<b>Reconfigure P3-related parameters</b><br>- Gaussian Blur<br>- Symmetric Avg (Final)];
        K --> I;
        J -- Yes --> L[4. Save with "Save" button];
    end
</code></pre>

<hr>
<h2>References</h2>
<ul>
    <li>George R. Heath, et al. "<a href="https://doi.org/10.1038/s41586-021-03551-x">Localization atomic force microscopy</a>". <i>Nature</i> 594, 385â€“390 (2021).</li>
    <li>Yining Jiang, et al. "<a href="https://doi.org/10.1038/s41594-024-01260-3">HS-AFM single-molecule structural biology uncovers basis of transporter wanderlust kinetics</a>". <i>Nature Structural & Molecular Biology</i> 31, 1286â€“1295 (2024).</li>
</ul>
"""

HELP_HTML_JA = """
<h1>L-AFM Analysis (Localization AFM)</h1>

<h2>æ¦‚è¦</h2>
<p>L-AFM (Localization Atomic Force Microscopy) è§£æã¯ã€AFMã®æ™‚ç³»åˆ—ç”»åƒï¼ˆå‹•ç”»ï¼‰ã‹ã‚‰å€‹ã€…ã®åˆ†å­ã‚„æ§‹é€ ç‰©ã®è¼åº¦ãƒ”ãƒ¼ã‚¯ã‚’é«˜ç²¾åº¦ã«æ¤œå‡ºã—ã€ãã®ä½ç½®æƒ…å ±ã‚’å¤šæ•°é›†ã‚ã¦å†æ§‹æˆã™ã‚‹ã“ã¨ã§ã€å…ƒã®ç”»åƒã®è§£åƒåº¦ã‚’è¶…ãˆã‚‹ã€Œè¶…è§£åƒç”»åƒã€ã‚’æ§‹ç¯‰ã™ã‚‹æŠ€è¡“ã§ã™ã€‚ã“ã®ãƒ‘ãƒãƒ«ã§ã¯ã€ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã‹ã‚‰ç”»åƒå†æ§‹æˆã¾ã§ã®ä¸€é€£ã®å‡¦ç†ã‚’ã€ã‚¹ãƒ†ãƒƒãƒ—ãƒ»ãƒã‚¤ãƒ»ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè¡Œã§ãã¾ã™ã€‚</p>

<h2>ã‚¢ã‚¯ã‚»ã‚¹æ–¹æ³•</h2>
<ul>
    <li><strong>ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ãƒ¡ãƒ‹ãƒ¥ãƒ¼:</strong> Load Plugin... â†’ <code>plugins/LAFMAnalysis.py</code> ã‚’é¸æŠã—ã€Plugin â†’ L-AFM Analysis ã‚’å®Ÿè¡Œ</li>
</ul>

<h2>å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—ã®æ¦‚è¦</h2>
<p>L-AFMè§£æã¯ã€ä¸»ã«3ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ§‹æˆã•ã‚Œã¾ã™ã€‚å„ã‚¹ãƒ†ãƒƒãƒ—ã®ãƒœã‚¿ãƒ³ã‚’é †ç•ªã«å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚</p>
<div class="step">
    <strong>Step 1: Preprocessing 1 (ãƒ”ãƒ¼ã‚¯æ¤œå‡º)</strong><br>
    AFMå‹•ç”»ã®å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰ã€è¨­å®šã•ã‚ŒãŸæ¡ä»¶ã«åŸºã¥ã„ã¦è¼åº¦ãŒé«˜ã„ç‚¹ï¼ˆãƒ”ãƒ¼ã‚¯ï¼‰ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
</div>
<div class="step">
    <strong>Step 2: Preprocessing 2 (ç©ºé–“ã¸ã®å†æ§‹æˆ)</strong><br>
    Step 1ã§æ¤œå‡ºã•ã‚ŒãŸå…¨ã¦ã®ãƒ”ãƒ¼ã‚¯ã®åº§æ¨™ã‚’ã€é«˜è§£åƒåº¦ã®2Dã‚°ãƒªãƒƒãƒ‰ã¾ãŸã¯3Dãƒœã‚¯ã‚»ãƒ«ç©ºé–“ã«ãƒ—ãƒ­ãƒƒãƒˆã—ã¾ã™ã€‚
</div>
<div class="step">
    <strong>Step 3: Make LAFM Image (è¶…è§£åƒç”»åƒã®ç”Ÿæˆ)</strong><br>
    Step 2ã§ä½œæˆã—ãŸç‚¹æç”»ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã«ã€ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ã¼ã‹ã—ã‚’é©ç”¨ã—ã¦æ»‘ã‚‰ã‹ãªè¶…è§£åƒç”»åƒã«ä»•ä¸Šã’ã¾ã™ã€‚
</div>

<h2>æ–°æ©Ÿèƒ½: Zç¯„å›²è‡ªå‹•è¨­å®š</h2>
<p>L-AFMãƒ‘ãƒãƒ«ã«ã¯ã€è§£æç²¾åº¦ã¨ãƒ¦ãƒ¼ã‚¶ãƒ“ãƒªãƒ†ã‚£ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªZç¯„å›²æœ€é©åŒ–æ©Ÿèƒ½ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚</p>

<h3>Auto Z-Rangeãƒœã‚¿ãƒ³</h3>
<div class="feature-box">
    <h4>çµ±è¨ˆçš„Zç¯„å›²è¨ˆç®—</h4>
    <ul>
        <li><strong>è‡ªå‹•è¨ˆç®—:</strong> èª­ã¿è¾¼ã¾ã‚ŒãŸç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‚’è§£æã—ã€ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆã«åŸºã¥ã„ã¦æœ€é©ãªZ_minã¨Z_maxå€¤ã‚’æ±ºå®šã—ã¾ã™ã€‚</li>
        <li><strong>ãƒã‚¤ã‚ºãƒ¬ãƒ™ãƒ«è€ƒæ…®:</strong> ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢ã¨ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã‚’æ¨å®šã—ã¦é©åˆ‡ãªé–¾å€¤ã‚’è¨­å®šã—ã¾ã™ã€‚</li>
        <li><strong>ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¼ç‡:</strong> è¨ˆç®—ã•ã‚ŒãŸç¯„å›²ãŒãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã®é©åˆ‡ãªå‰²åˆã‚’ã‚«ãƒãƒ¼ã™ã‚‹ã“ã¨ã‚’ä¿è¨¼ã—ã¾ã™ã€‚</li>
        <li><strong>ç‰©ç†çš„å¦¥å½“æ€§:</strong> æœ€å°é–¾å€¤ï¼ˆ10 pmï¼‰ã‚’é©ç”¨ã—ã€è«–ç†çš„ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™ã€‚</li>
    </ul>
</div>

<h3>ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠ</h3>
<div class="feature-box">
    <h4>ç•°ãªã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—ç”¨ã®äº‹å‰å®šç¾©è¨­å®š</h4>
    <ul>
        <li><strong>General:</strong> ä¸€èˆ¬çš„ãªè§£æç”¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šï¼ˆZ_min: 0.1 nm, Z_max: 10.0 nmï¼‰</li>
        <li><strong>Proteins:</strong> å˜ä¸€ã‚¿ãƒ³ãƒ‘ã‚¯è³ªã‹ã‚‰å¤§ããªè¤‡åˆä½“ã¾ã§æœ€é©åŒ–ï¼ˆZ_min: 0.1 nm, Z_max: 10.0 nmï¼‰</li>
        <li><strong>DNA/RNA:</strong> æ ¸é…¸åˆ†å­ã«é©ã—ãŸè¨­å®šï¼ˆZ_min: 0.05 nm, Z_max: 3.0 nmï¼‰</li>
        <li><strong>Cells:</strong> ç´°èƒæ§‹é€ ã¨ã‚ªãƒ«ã‚¬ãƒãƒ©ç”¨ï¼ˆZ_min: 1.0 nm, Z_max: 100.0 nmï¼‰</li>
        <li><strong>Crystals:</strong> çµæ™¶è¡¨é¢ã¨æ¬ é™¥ç”¨ï¼ˆZ_min: 0.01 nm, Z_max: 50.0 nmï¼‰</li>
        <li><strong>Nanoparticles:</strong> ãƒŠãƒç²’å­ã¨å‡é›†ä½“ç”¨ï¼ˆZ_min: 0.5 nm, Z_max: 20.0 nmï¼‰</li>
    </ul>
</div>

<h3>ä½¿ç”¨æ–¹æ³•</h3>
<ol>
    <li><strong>ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿:</strong> ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã¨ã€Zç¯„å›²å€¤ãŒè‡ªå‹•çš„ã«è¨ˆç®—ãƒ»è¨­å®šã•ã‚Œã¾ã™ã€‚</li>
    <li><strong>æ‰‹å‹•èª¿æ•´:</strong> "Auto Z-Range"ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦å†è¨ˆç®—ã—ã¾ã™ã€‚</li>
    <li><strong>ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠ:</strong> ãƒ‰ãƒ­ãƒƒãƒ—ãƒ€ã‚¦ãƒ³ã‹ã‚‰é©åˆ‡ãªã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—ã‚’é¸æŠã—ã¦æ¨å¥¨è¨­å®šã‚’é©ç”¨ã—ã¾ã™ã€‚</li>
    <li><strong>ç¯„å›²è¡¨ç¤º:</strong> ç¾åœ¨ã®Zç¯„å›²ãŒãƒœã‚¿ãƒ³ã®æ¨ªã«è¡¨ç¤ºã•ã‚Œã€ç°¡å˜ã«å‚ç…§ã§ãã¾ã™ã€‚</li>
</ol>

<h2>Preprocessing 1ã¨2ã®é•ã„ã«ã¤ã„ã¦</h2>
<p>ã“ã®2ã¤ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯ã€L-AFMè§£æã«ãŠã‘ã‚‹ã€Œ<b>æ¤œå‡º</b>ã€ã¨ã€Œ<b>æç”»</b>ã€ã¨ã„ã†å…¨ãç•°ãªã‚‹å½¹å‰²ã‚’æ‹…ã£ã¦ã„ã¾ã™ã€‚</p>
<div class="feature-box">
    <h4>Preprocessing 1ï¼šãƒ”ãƒ¼ã‚¯ã®æ¢ç´¢ã¨æ¤œå‡º</h4>
    <ul>
        <li><strong>å…¥åŠ›</strong>: AFMã®æ™‚ç³»åˆ—ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ï¼ˆç”Ÿã®ãƒ”ã‚¯ã‚»ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼‰</li>
        <li><strong>å‡¦ç†å†…å®¹</strong>: å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€ã€Œã©ã“ã«åˆ†å­ãŒå­˜åœ¨ã—ãŸã‹ã€ã¨ã„ã†<b>åº§æ¨™æƒ…å ±</b>ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¾ã™ã€‚</li>
        <li><strong>å‡ºåŠ›</strong>: æ¤œå‡ºã•ã‚ŒãŸå…¨ãƒ”ãƒ¼ã‚¯ã®åº§æ¨™ãƒ»è¼åº¦ãƒ»ãƒ•ãƒ¬ãƒ¼ãƒ ç•ªå·ãªã©ã‚’ã¾ã¨ã‚ãŸãƒªã‚¹ãƒˆï¼ˆä½æ‰€éŒ²ã®ã‚ˆã†ãªã‚‚ã®ï¼‰ã€‚</li>
        <li><strong>ä¸€è¨€ã§è¨€ã†ã¨</strong>: <b>ç”»åƒã‹ã‚‰ã€Œåˆ†å­ã®ä½æ‰€éŒ²ã€ã‚’ä½œã‚‹ä½œæ¥­ã§ã™ã€‚</b></li>
    </ul>
</div>
<div class="feature-box">
    <h4>Preprocessing 2ï¼šåº§æ¨™ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”»åƒã¸ã®å†æ§‹æˆ</h4>
    <ul>
        <li><strong>å…¥åŠ›</strong>: Preprocessing 1 ãŒå‡ºåŠ›ã—ãŸãƒ”ãƒ¼ã‚¯ã®åº§æ¨™ãƒªã‚¹ãƒˆã€‚<b>ï¼ˆã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã¯å…ƒã®ç”»åƒã¯ä¸€åˆ‡è¦‹ã¾ã›ã‚“ï¼‰</b></li>
        <li><strong>å‡¦ç†å†…å®¹</strong>: æ–°ã—ã„é«˜è§£åƒåº¦ã®ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’ç”¨æ„ã—ã€å…¥åŠ›ã•ã‚ŒãŸåº§æ¨™ãƒªã‚¹ãƒˆã®å ´æ‰€ã«ç‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆï¼ˆæŠ•ç¥¨ï¼‰ã—ã¦ã„ãã¾ã™ã€‚</li>
        <li><strong>å‡ºåŠ›</strong>: ãƒ”ãƒ¼ã‚¯ã®å­˜åœ¨å¯†åº¦ã‚’è¡¨ç¾ã—ãŸç‚¹æç”»ã®ã‚ˆã†ãªãƒ‡ãƒ¼ã‚¿ã€‚</li>
        <li><strong>ä¸€è¨€ã§è¨€ã†ã¨</strong>: <b>ã€Œåˆ†å­ã®ä½æ‰€éŒ²ã€ã‚’å…ƒã«ã€Œåˆ†å¸ƒå›³ã€ã‚’ä½œæˆã™ã‚‹ä½œæ¥­ã§ã™ã€‚</b></li>
    </ul>
</div>

<h2>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚°ãƒ«ãƒ¼ãƒ—ã¨è¨­å®š</h2>

<h3>Peak Filteringã‚°ãƒ«ãƒ¼ãƒ—</h3>
<div class="feature-box">
    <h4>Filter Mode</h4>
    <ul>
        <li><strong>Absolute Height (nm):</strong> ãƒ”ãƒ¼ã‚¯ã‚’çµ¶å¯¾çš„ãªé«˜ã•å€¤ï¼ˆãƒŠãƒãƒ¡ãƒ¼ãƒˆãƒ«ï¼‰ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚</li>
        <li><strong>Statistics (Mean + N x Std Dev):</strong> å¹³å‡å€¤ã¨æ¨™æº–åå·®ã‚’ä½¿ç”¨ã—ãŸçµ±è¨ˆçš„åŸºæº–ã§ãƒ”ãƒ¼ã‚¯ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã—ã¾ã™ã€‚</li>
    </ul>

    <h4>Zç¯„å›²è¨­å®šï¼ˆæ–°æ©Ÿèƒ½ï¼‰</h4>
    <ul>
        <li><strong>Auto Z-Rangeãƒœã‚¿ãƒ³:</strong> èª­ã¿è¾¼ã¾ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœ€é©ãªZ_minã¨Z_maxå€¤ã‚’è‡ªå‹•è¨ˆç®—ã—ã¾ã™ã€‚</li>
        <li><strong>Z_min (nm):</strong> ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã®æœ€å°é«˜ã•é–¾å€¤ã€‚</li>
        <li><strong>Z_max (nm):</strong> ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã®æœ€å¤§é«˜ã•é–¾å€¤ã€‚</li>
        <li><strong>ç¯„å›²è¡¨ç¤º:</strong> ç¾åœ¨ã®Zç¯„å›²ã®å¹…ã‚’ç°¡å˜ã«å‚ç…§ã§ãã‚‹ã‚ˆã†ã«è¡¨ç¤ºã—ã¾ã™ã€‚</li>
    </ul>

    <h4>ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠï¼ˆæ–°æ©Ÿèƒ½ï¼‰</h4>
    <ul>
        <li><strong>General:</strong> ä¸€èˆ¬çš„ãªè§£æç”¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã€‚</li>
        <li><strong>Proteins:</strong> ã‚¿ãƒ³ãƒ‘ã‚¯è³ªè§£æã«æœ€é©åŒ–ã€‚</li>
        <li><strong>DNA/RNA:</strong> æ ¸é…¸åˆ†å­ã«é©ã—ãŸè¨­å®šã€‚</li>
        <li><strong>Cells:</strong> ç´°èƒæ§‹é€ ã¨ã‚ªãƒ«ã‚¬ãƒãƒ©ç”¨ã€‚</li>
        <li><strong>Crystals:</strong> çµæ™¶è¡¨é¢ã¨æ¬ é™¥ç”¨ã€‚</li>
        <li><strong>Nanoparticles:</strong> ãƒŠãƒç²’å­ã¨å‡é›†ä½“ç”¨ã€‚</li>
    </ul>

    <h4>N Factor</h4>
    <ul>
        <li><strong>ç›®çš„:</strong> çµ±è¨ˆçš„ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰ã§ã®æ¨™æº–åå·®ã®ä¹—æ•°ã€‚</li>
        <li><strong>è‡ªå‹•è¨ˆç®—:</strong> ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ™‚ã«æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰è‡ªå‹•è¨ˆç®—ã•ã‚Œã¾ã™ã€‚</li>
    </ul>
</div>

<h2>ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å¤‰æ›´ã¨å†å®Ÿè¡Œã®åˆ¤æ–­</h2>
<p>ä¸Šè¨˜ã®é•ã„ã‹ã‚‰ã€å¤‰æ›´ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒã€Œæ¤œå‡ºã€ã«å½±éŸ¿ã™ã‚‹ã®ã‹ã€ã€Œæç”»ã€ã«å½±éŸ¿ã™ã‚‹ã®ã‹ã«ã‚ˆã£ã¦ã€ã‚„ã‚Šç›´ã™ã¹ãã‚¹ãƒ†ãƒƒãƒ—ãŒå¤‰ã‚ã‚Šã¾ã™ã€‚</p>

<h3>Preprocessing 1ã‹ã‚‰å†å®Ÿè¡ŒãŒå¿…è¦ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>
<p><b>ã€Œãƒ”ãƒ¼ã‚¯ã®æ¤œå‡ºæ¡ä»¶ã€ãã®ã‚‚ã®ã«å¤‰æ›´ãŒã‚ã£ãŸå ´åˆ</b>ã¯ã€æœ€åˆã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã‚„ã‚Šç›´ã™å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚</p>
<ul>
    <li><b>Drift Correction</b> ã‚°ãƒ«ãƒ¼ãƒ—ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
    <li><b>Peak Filtering</b> ã‚°ãƒ«ãƒ¼ãƒ—ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
    <li><b>Local Maxima</b> ã‚°ãƒ«ãƒ¼ãƒ—ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
    <li><b>Subpixel Localization</b> ã‚°ãƒ«ãƒ¼ãƒ—ã® "Enable Subpixel Localization" ã¨ "Scale"</li>
</ul>

<h3>Preprocessing 2ã‹ã‚‰ã§è‰¯ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>
<p><b>ã€Œæ¤œå‡ºæ¸ˆã¿ã®ãƒ”ãƒ¼ã‚¯ã‚’ã©ã†æç”»ã™ã‚‹ã‹ã€ã¨ã„ã†æ¡ä»¶ã®ã¿å¤‰æ›´ã—ãŸå ´åˆ</b>ã¯ã€æ™‚é–“ã®ã‹ã‹ã‚‹ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã‚’ã‚¹ã‚­ãƒƒãƒ—ã§ãã¾ã™ã€‚</p>
<ul>
    <li><b>Mode</b> ("2D" â‡” "3D" ã®åˆ‡ã‚Šæ›¿ãˆ)</li>
    <li><b>Subpixel Localization</b> ã‚°ãƒ«ãƒ¼ãƒ—ã® "XY Resolution" ã¨ "Z Resolution"</li>
    <li><b>Symmetric Averaging</b> ã‚°ãƒ«ãƒ¼ãƒ—ã® "During Reconstruction (Prep 2)" ã®è¨­å®š</li>
</ul>

<h3>Make LAFM Imageã‹ã‚‰ã§è‰¯ã„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</h3>
<p><b>ã€Œå†æ§‹æˆã•ã‚ŒãŸç”»åƒã®ä»•ä¸Šã’æ–¹ã€ã®ã¿å¤‰æ›´ã—ãŸå ´åˆ</b>ã¯ã€æœ€ã‚‚é«˜é€Ÿãªã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã§çµæ§‹ã§ã™ã€‚</p>
<ul>
    <li><b>Gaussian Blur</b> ã‚°ãƒ«ãƒ¼ãƒ—ã®å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿</li>
    <li><b>Symmetric Averaging</b> ã‚°ãƒ«ãƒ¼ãƒ—ã® "On Final LAFM Image" ã®è¨­å®š</li>
</ul>

<h2>å®Ÿè·µçš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆï¼‰</h2>
<p>ä»¥ä¸‹ã«ã€ä¸Šè¨˜ã®åˆ†å²æ¡ä»¶ã‚’ç››ã‚Šè¾¼ã‚“ã å®Ÿè·µçš„ãªè§£æãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ç¤ºã—ã¾ã™ã€‚</p>
<pre><code>
graph TD
    subgraph åˆæœŸè¨­å®š
        A[L-AFMãƒ‘ãƒãƒ«ã‚’é–‹ã] --> B{ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š};
    end

    subgraph Step 1: ãƒ”ãƒ¼ã‚¯æ¤œå‡º
        B --> C[1. Preprocessing 1 ã‚’å®Ÿè¡Œ];
        C --> D{ãƒ”ãƒ¼ã‚¯æ¤œå‡ºçµæœã¯å¦¥å½“ã‹ï¼Ÿ<br>(æ¤œå‡ºæ•°ã‚„ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ç”»åƒã‚’ç¢ºèª)};
        D -- No --> E[<b>P1é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å†è¨­å®š</b><br>- Drift Correction<br>- Peak Filtering<br>- Local Maxima<br>- Subpixel (Enable/Scale)];
        E --> C;
    end

    subgraph Step 2: å†æ§‹æˆ
        D -- Yes --> F[2. Preprocessing 2 ã‚’å®Ÿè¡Œ];
        F --> G{å†æ§‹æˆçµæœã¯å¦¥å½“ã‹ï¼Ÿ<br>(ç”»åƒã®å¯†åº¦ã‚„åˆ†å¸ƒã‚’ç¢ºèª)};
        G -- No --> H[<b>P2é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å†è¨­å®š</b><br>- Mode (2D/3D)<br>- Subpixel Resolution<br>- Symmetric Avg (Prep 2)];
        H --> F;
    end

    subgraph Step 3: ç”»åƒç”Ÿæˆã¨ä¿å­˜
        G -- Yes --> I[3. Make LAFM Image ã‚’å®Ÿè¡Œ];
        I --> J{æœ€çµ‚ç”»åƒã¯æº€è¶³ã‹ï¼Ÿ<br>(ç”»åƒã®æ»‘ã‚‰ã‹ã•ã‚„è¦‹ãŸç›®ã‚’ç¢ºèª)};
        J -- No --> K[<b>P3é–¢é€£ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å†è¨­å®š</b><br>- Gaussian Blur<br>- Symmetric Avg (Final)];
        K --> I;
        J -- Yes --> L[4. Save ã§ä¿å­˜];
    end
</code></pre>

<hr>
<h2>å‚è€ƒæ–‡çŒ®</h2>
<ul>
    <li>George R. Heath, et al. "<a href="https://doi.org/10.1038/s41586-021-03551-x">Localization atomic force microscopy</a>". <i>Nature</i> 594, 385â€“390 (2021).</li>
    <li>Yining Jiang, et al. "<a href="https://doi.org/10.1038/s41594-024-01260-3">HS-AFM single-molecule structural biology uncovers basis of transporter wanderlust kinetics</a>". <i>Nature Structural & Molecular Biology</i> 31, 1286â€“1295 (2024).</li>
</ul>
"""

# (LAFMWorkerã‚¯ãƒ©ã‚¹ã¯å¤‰æ›´ã‚ã‚Šã¾ã›ã‚“)
class LAFMWorker(QtCore.QObject):
    finished = QtCore.pyqtSignal(object)
    progress = QtCore.pyqtSignal(int, str)
    error = QtCore.pyqtSignal(str)
    plot_signal = QtCore.pyqtSignal(np.ndarray, str)

    def __init__(self, function, *args, **kwargs):
        super().__init__()
        self.function = function
        self.args = args
        self.kwargs = kwargs

    @QtCore.pyqtSlot()
    def run(self):
        try:
            self.kwargs['progress_signal'] = self.progress
            self.kwargs['plot_signal'] = self.plot_signal
            result = self.function(*self.args, **self.kwargs)
            self.finished.emit(result)
        except Exception as e:
            import traceback
            self.error.emit(f"{e}\n\n{traceback.format_exc()}")

# --- â–¼â–¼â–¼ Voxel3DViewerã‚¯ãƒ©ã‚¹ã‚’ã€ä»¥ä¸‹ã®æ–°ã—ã„å®šç¾©ã«ä¸¸ã”ã¨ç½®ãæ›ãˆã¦ãã ã•ã„ â–¼â–¼â–¼ ---
class Voxel3DViewer(QtWidgets.QWidget):
    """PyVistaã‚’ä½¿ã£ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–3Dãƒœã‚¯ã‚»ãƒ«ãƒ“ãƒ¥ãƒ¼ã‚¢ï¼ˆZã‚¹ã‚±ãƒ¼ãƒ«ä¿®æ­£ç‰ˆï¼‰"""
    was_closed = QtCore.pyqtSignal()

    def __init__(self, parent=None):
        super().__init__(parent)
        self.setWindowTitle("3D Voxel Viewer")
        self.setMinimumSize(600, 500)
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ç™»éŒ²
        try:
            from window_manager import register_pyNuD_window
            register_pyNuD_window(self, "sub")
        except ImportError:
            pass

        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã®åˆæœŸåŒ–
        self.plotter = None
        self.volume_data = None
        self.original_spacing = (1.0, 1.0, 1.0)
        
        # ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
        main_layout = QtWidgets.QVBoxLayout(self)
        main_layout.setContentsMargins(5, 5, 5, 5)

        # 3Dè¡¨ç¤ºã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆ - ã‚ˆã‚Šå®‰å…¨ãªåˆæœŸåŒ–
        try:
            # æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®PyVistaã«å¯¾å¿œ
            self.plotter = QtInteractor(self)
            
            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¿œã˜ã¦é©åˆ‡ãªã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã‚’è¿½åŠ 
            if hasattr(self.plotter, 'interactor'):
                main_layout.addWidget(self.plotter.interactor)
            elif hasattr(self.plotter, 'app_window'):
                main_layout.addWidget(self.plotter.app_window)
            else:
                main_layout.addWidget(self.plotter)
                
        except Exception as e:
            print(f"[ERROR] Failed to initialize QtInteractor: {e}")
            import traceback
            traceback.print_exc()
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: é€šå¸¸ã®PyVista plotterã‚’ä½¿ç”¨
            self.plotter = pv.Plotter()
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
            error_label = QtWidgets.QLabel("3D Viewer initialization failed. Please check PyVista installation.")
            error_label.setStyleSheet("color: red; font-weight: bold;")
            main_layout.addWidget(error_label)
            return

        # Zã‚¹ã‚±ãƒ¼ãƒ«èª¿æ•´ç”¨ã®UI
        control_layout = QtWidgets.QHBoxLayout()
        control_layout.addWidget(QtWidgets.QLabel("Z-Scale Exaggeration:"))
        self.z_scale_spin = QtWidgets.QDoubleSpinBox(value=1.0, minimum=0.1, maximum=100.0, singleStep=0.5, decimals=1)
        self.z_scale_spin.valueChanged.connect(self._update_z_scale) # å€¤ã®å¤‰æ›´ã‚’æ¤œçŸ¥
        control_layout.addWidget(self.z_scale_spin)
        control_layout.addStretch()
        
        main_layout.addLayout(control_layout)

    def update_data(self, volume_data, spacing=(1.0, 1.0, 1.0)):
        """æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã£ãŸã¨ãã«å‘¼ã°ã‚Œã‚‹ãƒ¡ã‚½ãƒƒãƒ‰"""
        if not PYVISTA_AVAILABLE: return
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã«ä¿å­˜
        self.volume_data = volume_data
        self.original_spacing = spacing
        
        # UIã®åˆæœŸå€¤ã‚’ãƒªã‚»ãƒƒãƒˆã—ã€ã‚·ãƒ¼ãƒ³ã‚’å†æç”»
        self.z_scale_spin.setValue(1.0)
        self._redraw_scene()

    @QtCore.pyqtSlot()
    def _update_z_scale(self):
        """Zã‚¹ã‚±ãƒ¼ãƒ«ã‚¹ãƒ”ãƒ³ãƒœãƒƒã‚¯ã‚¹ã®å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸã¨ãã«ã€ã‚·ãƒ¼ãƒ³ã‚’å†æç”»ã™ã‚‹"""
        self._redraw_scene()

    def _redraw_scene(self):
        """ç¾åœ¨ã®è¨­å®šã§3Dã‚·ãƒ¼ãƒ³ã‚’å†æç”»ã™ã‚‹å†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰"""
        if self.volume_data is None or self.plotter is None:
            return
            
        try:
            self.plotter.clear()
            
            grid = pv.ImageData()
            
            vol_transposed = self.volume_data.transpose(1, 0, 2)
            grid.dimensions = vol_transposed.shape
            
            # Zã‚¹ã‚±ãƒ¼ãƒ«ã‚’é©ç”¨ã—ãŸspacingã‚’è¨ˆç®—
            z_scale_factor = self.z_scale_spin.value()
            effective_spacing = (
                self.original_spacing[0], 
                self.original_spacing[1], 
                self.original_spacing[2] * z_scale_factor
            )
            grid.spacing = effective_spacing
            
            grid.point_data["values"] = vol_transposed.flatten(order="F")

            # ã‚«ãƒ©ãƒ¼ãƒãƒ¼ã¯éè¡¨ç¤º
            self.plotter.add_volume(grid, cmap="magma", opacity="sigmoid", show_scalar_bar=False)
            
            # ãƒ«ãƒ¼ãƒ©ãƒ¼ï¼ˆè»¸ï¼‰ã‚’è¿½åŠ 
            xmin, xmax, ymin, ymax, zmin, zmax = grid.bounds
            font_size = 10
            ruler_x = self.plotter.add_ruler([xmin, ymin, zmin], [xmax, ymin, zmin], label_format="%.1f", title="X (nm)")
            ruler_x.GetLabelTextProperty().SetFontSize(font_size); ruler_x.GetTitleTextProperty().SetFontSize(font_size)
            ruler_y = self.plotter.add_ruler([xmin, ymin, zmin], [xmin, ymax, zmin], label_format="%.1f", title="Y (nm)")
            ruler_y.GetLabelTextProperty().SetFontSize(font_size); ruler_y.GetTitleTextProperty().SetFontSize(font_size)
            z_unit = get_z_unit()
            ruler_z = self.plotter.add_ruler([xmin, ymin, zmin], [xmin, ymin, zmax], label_format="%.1f", title=f"Z ({z_unit})")
            ruler_z.GetLabelTextProperty().SetFontSize(font_size); ruler_z.GetTitleTextProperty().SetFontSize(font_size)
            
            self.plotter.reset_camera()
            self.plotter.render()
        except Exception as e:
            print(f"[ERROR] Failed to redraw 3D scene: {e}")
            import traceback
            traceback.print_exc()

    def closeEvent(self, event):
        self.was_closed.emit()
        try:
            if self.plotter is not None:
                self.plotter.close()
        except Exception as e:
            print(f"[ERROR] Failed to close plotter: {e}")
        super().closeEvent(event)

class LAFMPanelWindow(QtWidgets.QWidget):
    # __init__ãƒ¡ã‚½ãƒƒãƒ‰ã¯å¤‰æ›´ãªã—
    def __init__(self, parent=None):
        super().__init__()
        self.setWindowFlags(QtCore.Qt.Window)
        self.main_window = parent
        self.setWindowTitle("L-AFM Analysis")
        self.setMinimumSize(600, 420)
        
        # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã«ç™»éŒ²
        try:
            from window_manager import register_pyNuD_window
            register_pyNuD_window(self, "sub")
        except ImportError:
            pass

        # --- â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã‚’æ­£ã—ãæ¢ã—å‡ºã—ã¦å¾©å…ƒã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯ â–¼â–¼â–¼ ---
        window_settings = getattr(gv, 'windowSettings', {})
        saved_settings = None
        
        # "LAFMPanelWindow"ã§å§‹ã¾ã‚‹ã‚­ãƒ¼ã‚’å…¨ã¦æ¢ã—ã€æœ€åˆã«è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã‚’ä½¿ç”¨ã™ã‚‹
        for key, settings in window_settings.items():
            if key.startswith(self.__class__.__name__):
                saved_settings = settings
                break

        # ã€é‡è¦ã€‘'visible'ã®ãƒã‚§ãƒƒã‚¯ã‚’å‰Šé™¤ã—ã€è¨­å®šãŒå­˜åœ¨ã™ã‚Œã°å¿…ãšä½ç½®ã‚’å¾©å…ƒã™ã‚‹
        if saved_settings:
            try:
                self.setGeometry(
                    saved_settings.get('x', 150),
                    saved_settings.get('y', 150),
                    saved_settings.get('width', 600),
                    saved_settings.get('height', 420)
                )
            except Exception as e:
                print(f"Failed to set geometry from saved settings: {e}")
        else:
            # ä¿å­˜ã•ã‚ŒãŸè¨­å®šãŒãªã„å ´åˆã®ã¿ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä½ç½®ã«è¡¨ç¤º
            if self.main_window:
                main_geo = self.main_window.geometry()
                self.move(main_geo.x() + main_geo.width() + 10, main_geo.y())
        # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---

        self.params = {}
        self.original_image_stack = None
        self.scale_info = None
        self.detection_summary = None
        self.processed_shape = None

        self.processed_image_stack = None 
        self.reconstruction = None
        self.reconstruction_image = None
        self.final_lafm_image = None
        self.viewer_3d_window = None

        self.top_last_np_array = None
        self.bottom_last_np_array = None
        self.top_last_aspect_ratio = 1.0
        self.bottom_last_aspect_ratio = 1.0

        self.initUI()
        self.start_initial_load()
    
    def start_initial_load(self):
        """éåŒæœŸã§ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚’é–‹å§‹ã™ã‚‹"""
        self._update_status("Loading image data...", color="darkorange")
        self.progress_bar.setRange(0, 100) # ã“ã®æ™‚ç‚¹ã§ã¯ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã¯å‹•ã‹ãªã„
        self._run_in_thread(
            self.load_initial_data,
            self._on_initial_load_finished
        )

    def resizeEvent(self, event):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã®ãƒªã‚µã‚¤ã‚ºæ™‚ã«ç”»åƒã®å†æç”»ã‚’è¡Œã†"""
        super().resizeEvent(event)

        if self.top_last_np_array is not None:
            self._display_image(self.top_last_np_array, target='top')
        
        # è¡¨ç¤ºã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã¯ã€ãƒ¢ãƒ¼ãƒ‰ã«ã‚ˆã£ã¦å…ƒã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒç•°ãªã‚‹ãŸã‚ã€
        # reconstructionãŒå­˜åœ¨ã™ã‚‹ã‹ã©ã†ã‹ã§åˆ¤å®šã™ã‚‹
        if hasattr(self, 'reconstruction') and self.reconstruction is not None:
             if self.params.get('mode', '2D') == '2D':
                display_img = np.sum(self.reconstruction, axis=2)
             else:
                display_img = np.max(self.reconstruction, axis=2)
             self._display_image(display_img, target='bottom')
            
    def _auto_calculate_z_range(self, image_stack):
        """ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‹ã‚‰é©åˆ‡ãªZ_minã¨Z_maxã‚’è‡ªå‹•è¨ˆç®—"""
        try:
            # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã‹ã‚‰çµ±è¨ˆæƒ…å ±ã‚’å–å¾—
            all_data = image_stack.flatten()
            
            # ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢ã®æ¨å®šï¼ˆä¸‹ä½10%ã®æ¨™æº–åå·®ï¼‰
            noise_threshold = np.percentile(all_data, 10)
            noise_data = all_data[all_data <= noise_threshold]
            noise_std = np.std(noise_data) if len(noise_data) > 100 else np.std(all_data) * 0.1
            
            # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆä¸‹ä½5%ã®å¹³å‡ï¼‰
            baseline = np.mean(all_data[all_data <= np.percentile(all_data, 5)])
            
            # Z_min: ãƒã‚¤ã‚ºãƒ•ãƒ­ã‚¢ + 3Ïƒ
            z_min_noise = baseline + 3 * noise_std
            z_min_percentile = np.percentile(all_data, 2)  # ä¸‹ä½2%
            z_min = max(z_min_noise, z_min_percentile, 0.01)  # æœ€å°10pm
            
            # Z_max: ä¸Šä½95%ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«
            z_max = np.percentile(all_data, 95)
            
            # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            if z_max <= z_min:
                data_range = np.max(all_data) - np.min(all_data)
                z_max = z_min + max(0.1, data_range * 0.5)
            
            # ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¼ç‡ã®è¨ˆç®—
            coverage = np.sum((all_data >= z_min) & (all_data <= z_max)) / len(all_data) * 100
            
            #print(f"[Z-Range Auto] Recommended: Z_min={z_min:.3f}nm, Z_max={z_max:.3f}nm")
            #print(f"[Z-Range Auto] Data coverage: {coverage:.1f}%")
            #print(f"[Z-Range Auto] Noise level: {noise_std:.4f}nm")
            
            return z_min, z_max
            
        except Exception as e:
            #print(f"[ERROR] Z-range auto calculation failed: {e}")
            return 0.1, 5.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

    def _manual_auto_z_range(self):
        """æ‰‹å‹•ã§Zç¯„å›²ã‚’å†è¨ˆç®—ã™ã‚‹ãƒœã‚¿ãƒ³ã®å‡¦ç†"""
        if self.original_image_stack is not None:
            z_min_auto, z_max_auto = self._auto_calculate_z_range(self.original_image_stack)
            self.z_min_spin.setValue(z_min_auto)
            self.z_max_spin.setValue(z_max_auto)
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            data_range = z_max_auto - z_min_auto
            if hasattr(self, 'z_stats_label'):
                self.z_stats_label.setText(f"Range: {data_range:.3f}nm")
            
            self._update_status(f"Z-range updated: {z_min_auto:.3f}-{z_max_auto:.3f}nm", color="info")
        else:
            QtWidgets.QMessageBox.warning(self, "No Data", "ç”»åƒãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    # ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—åˆ¥ã®æ¨å¥¨è¨­å®š
    SAMPLE_TYPE_Z_RECOMMENDATIONS = {
        "General": {"z_min": 0.1, "z_max": 10.0, "desc": "General purpose settings"},
        "Proteins": {"z_min": 0.1, "z_max": 10.0, "desc": "Single proteins to large complexes"},
        "DNA/RNA": {"z_min": 0.05, "z_max": 3.0, "desc": "DNA molecules and nucleic acids"},
        "Cells": {"z_min": 1.0, "z_max": 100.0, "desc": "Cellular structures and organelles"},
        "Crystals": {"z_min": 0.01, "z_max": 50.0, "desc": "Crystal surfaces and defects"},
        "Nanoparticles": {"z_min": 0.5, "z_max": 20.0, "desc": "Nanoparticles and aggregates"}
    }

    def _on_sample_type_changed(self, sample_type):
        """ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—ãŒå¤‰æ›´ã•ã‚ŒãŸæ™‚ã®å‡¦ç†"""
        if sample_type in self.SAMPLE_TYPE_Z_RECOMMENDATIONS:
            settings = self.SAMPLE_TYPE_Z_RECOMMENDATIONS[sample_type]
            self.z_min_spin.setValue(settings["z_min"])
            self.z_max_spin.setValue(settings["z_max"])
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            data_range = settings["z_max"] - settings["z_min"]
            if hasattr(self, 'z_stats_label'):
                self.z_stats_label.setText(f"Range: {data_range:.3f}nm")
            
            self._update_status(f"Applied {sample_type} settings: {settings['desc']}", color="info")

    def _on_initial_load_finished(self, result):
        """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†å¾Œã®å‡¦ç†ï¼ˆZç¯„å›²è‡ªå‹•è¨­å®šçµ±åˆç‰ˆï¼‰"""
        stack, scale_info = result
        if stack is not None:
            self.original_image_stack = stack
            self.scale_info = scale_info
            self.processed_shape = stack.shape
            
            # ğŸ”¥ Zç¯„å›²ã®è‡ªå‹•è¨­å®šã‚’è¿½åŠ 
            z_min_auto, z_max_auto = self._auto_calculate_z_range(stack)
            self.z_min_spin.setValue(z_min_auto)
            self.z_max_spin.setValue(z_max_auto)
            
            # çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°
            data_range = z_max_auto - z_min_auto
            if hasattr(self, 'z_stats_label'):
                self.z_stats_label.setText(f"Range: {data_range:.3f}nm")
            
            self._update_status(
                f"{stack.shape[2]} frames loaded. Z-range auto-set: {z_min_auto:.3f}-{z_max_auto:.3f}nm. Ready for Preprocessing 1.", 
                color="green"
            )
            self._display_image(self.original_image_stack[:, :, 0], target='bottom')
            
            # Nã®åˆæœŸå€¤ã‚’è¨ˆç®—ï¼ˆæ—¢å­˜ã‚³ãƒ¼ãƒ‰ï¼‰
            try:
                first_frame = self.original_image_stack[:, :, 0]
                processed_first_frame = first_frame - np.min(first_frame)
                mean = np.mean(processed_first_frame); std = np.std(processed_first_frame)
                if std > 1e-9:
                    threshold = np.percentile(processed_first_frame, 99.9)
                    calculated_n = (threshold - mean) / std
                    self.std_dev_factor_spin.setValue(calculated_n)
            except Exception as e:
                self._update_status(f"Could not auto-set N: {e}", color="warning")
            
            # Preprocessing 1 ãƒœã‚¿ãƒ³ã‚’æœ‰åŠ¹åŒ–
            self.btn_prep1.setEnabled(True)
        else:
            self._update_status("Failed to load image stack.", color="red", level=1)

    # initUI: ãƒ¡ãƒ‹ãƒ¥ãƒ¼ãƒãƒ¼ï¼ˆHelp â†’ Manualï¼‰ã‚’ä¸Šéƒ¨ã«é…ç½®ã—ã€æ—¢å­˜ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã¯ content_widget ã«æ ¼ç´
    def initUI(self):
        main_layout = QtWidgets.QHBoxLayout()
        main_layout.setContentsMargins(5, 5, 5, 5)
        splitter = QtWidgets.QSplitter(QtCore.Qt.Horizontal)

        control_widget = QtWidgets.QScrollArea()
        control_widget.setWidgetResizable(True); control_widget.setMinimumWidth(340); control_widget.setMaximumWidth(400)
        scroll_content = QtWidgets.QWidget()
        control_layout = QtWidgets.QVBoxLayout(scroll_content)
        control_layout.setAlignment(QtCore.Qt.AlignTop); control_layout.setSpacing(6)
        control_widget.setWidget(scroll_content)

        button_grid_layout = QtWidgets.QGridLayout()
        self.btn_prep1 = QtWidgets.QPushButton("1. Preprocessing 1")
        self.btn_prep2 = QtWidgets.QPushButton("2. Preprocessing 2")
        self.btn_make_img = QtWidgets.QPushButton("3. Make LAFM Image")
        self.btn_save = QtWidgets.QPushButton("Save")
        button_grid_layout.addWidget(self.btn_prep1, 0, 0); button_grid_layout.addWidget(self.btn_prep2, 0, 1)
        button_grid_layout.addWidget(self.btn_make_img, 1, 0); button_grid_layout.addWidget(self.btn_save, 1, 1)
        control_layout.addLayout(button_grid_layout)
        
        self.btn_prep1.setEnabled(False)
        self.btn_prep2.setEnabled(False); self.btn_make_img.setEnabled(False); self.btn_save.setEnabled(False)
        self.btn_prep1.clicked.connect(self.run_preprocessing1)
        self.btn_prep2.clicked.connect(self.run_preprocessing2)
        self.btn_make_img.clicked.connect(self.run_make_lafm_image)
        self.btn_save.clicked.connect(self._save_lafm_data)
        
        mode_layout = QtWidgets.QHBoxLayout()
        self.mode_combo = QtWidgets.QComboBox(); self.mode_combo.addItems(["2D", "3D"])
        self.show_3d_check = QtWidgets.QCheckBox("3D Display")
        mode_layout.addWidget(QtWidgets.QLabel("Mode:")); mode_layout.addWidget(self.mode_combo)
        mode_layout.addWidget(self.show_3d_check)
        mode_layout.addStretch()
        control_layout.addLayout(mode_layout)

        self.mode_combo.currentIndexChanged.connect(self._on_mode_changed)
        self.show_3d_check.toggled.connect(self._handle_3d_display_toggle)

        self.status_label = QtWidgets.QLabel("Ready. Load data to start.")
        self.status_label.setStyleSheet("font-weight: bold; color: blue;"); self.status_label.setWordWrap(True)
        control_layout.addWidget(self.status_label)

        self._on_mode_changed(0)
        
        def create_form_group_box(title, checkable=False):
            group = QtWidgets.QGroupBox(title)
            group.setCheckable(checkable)
            if checkable: group.setChecked(False)
            layout = QtWidgets.QFormLayout(group)
            layout.setLabelAlignment(QtCore.Qt.AlignLeft); layout.setFormAlignment(QtCore.Qt.AlignLeft | QtCore.Qt.AlignTop)
            layout.setSpacing(5); layout.setContentsMargins(8, 10, 8, 8)
            return group, layout
        
        # â–¼â–¼â–¼ã€æ–°è¦è¿½åŠ ã€‘Drift Correction ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ Peak Filtering ã®å¾Œã«è¿½åŠ  â–¼â–¼â–¼
        drift_group, drift_layout = create_form_group_box("Drift Correction", checkable=True)
        drift_group.setChecked(False)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç„¡åŠ¹
        
        # ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ é¸æŠ
        self.drift_algorithm_combo = QtWidgets.QComboBox()
        self.drift_algorithm_combo.addItems(["Phase Correlation (Fast)", "Feature-based (Precise)"])
        drift_layout.addRow("Algorithm:", self.drift_algorithm_combo)
        
        # ä¿¡é ¼åº¦é–¾å€¤
        self.drift_threshold_spin = QtWidgets.QDoubleSpinBox(value=0.1, minimum=0.0, maximum=1.0, singleStep=0.01, decimals=3)
        self.drift_threshold_spin.setToolTip("Minimum confidence threshold for frame alignment (0.0 - 1.0)\nãƒ•ãƒ¬ãƒ¼ãƒ ä½ç½®åˆã‚ã›ã®æœ€å°ä¿¡é ¼åº¦é–¾å€¤ (0.0 - 1.0)")
        drift_layout.addRow("Min Confidence:", self.drift_threshold_spin)
        
        control_layout.addWidget(drift_group)
        self.drift_group = drift_group  # å¾Œã§å‚ç…§ã™ã‚‹ãŸã‚ä¿å­˜

        tol_group, tol_layout = create_form_group_box("Peak Filtering")
        self.filter_mode_combo = QtWidgets.QComboBox()
        self.filter_mode_combo.addItems(["Absolute Height (nm)", "Statistics (Mean + N x Std Dev)"])
        self.filter_mode_combo.currentIndexChanged.connect(self._on_filter_mode_changed)
        tol_layout.addRow("Filter Mode:", self.filter_mode_combo)
        self.std_dev_label = QtWidgets.QLabel("N factor:")
        self.std_dev_factor_spin = QtWidgets.QDoubleSpinBox(value=0.0, minimum=-5.0, maximum=20.0, singleStep=0.1)
        tol_layout.addRow(self.std_dev_label, self.std_dev_factor_spin)
        
        # Zç¯„å›²ã®è‡ªå‹•è¨­å®šãƒœã‚¿ãƒ³ï¼ˆä»–ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«ã¨åŒã˜å·¦ã®ä½ç½®ã«é…ç½®ï¼‰
        auto_z_button = QtWidgets.QPushButton("Auto Z-Range")
        auto_z_button.setMaximumWidth(120)
        auto_z_button.clicked.connect(self._manual_auto_z_range)
        auto_z_button.setToolTip("Recalculate optimal Z_min and Z_max from current data")
        
        # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆè¡¨ç¤ºãƒ©ãƒ™ãƒ«
        self.z_stats_label = QtWidgets.QLabel("Range: N/A")
        self.z_stats_label.setStyleSheet("color: gray;")
        
        # ã‚µãƒ³ãƒ—ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹
        self.sample_type_combo = QtWidgets.QComboBox()
        self.sample_type_combo.addItems(["General", "Proteins", "DNA/RNA", "Cells", "Crystals", "Nanoparticles"])
        self.sample_type_combo.currentTextChanged.connect(self._on_sample_type_changed)
        self.sample_type_combo.setToolTip("Select sample type for recommended Z-range settings")
        
        # Auto Z-Rangeãƒœã‚¿ãƒ³ã¨çµ±è¨ˆè¡¨ç¤ºã‚’æ¨ªä¸¦ã³ã«
        auto_z_row = QtWidgets.QHBoxLayout()
        auto_z_row.addWidget(auto_z_button)
        auto_z_row.addWidget(self.z_stats_label)
        auto_z_row.addStretch()
        tol_layout.addRow("Auto Z-Range:", auto_z_row)
        
        # Sampleé¸æŠã‚’åˆ¥ã®è¡Œã«é…ç½®
        sample_row = QtWidgets.QHBoxLayout()
        sample_row.addWidget(QtWidgets.QLabel("Sample:"))
        sample_row.addWidget(self.sample_type_combo)
        sample_row.addStretch()
        tol_layout.addRow("", sample_row)
        
        self.z_min_label = QtWidgets.QLabel("Z_min (nm):")
        self.z_min_spin = QtWidgets.QDoubleSpinBox(value=0.1, minimum=-1000, maximum=1000, singleStep=0.1)
        self.z_max_spin = QtWidgets.QDoubleSpinBox(value=5.0, minimum=-1000, maximum=1000, singleStep=0.1)
        self.z_min_spin.valueChanged.connect(self._on_z_range_changed); self.z_max_spin.valueChanged.connect(self._on_z_range_changed)
        self.crop_ratio_spin = QtWidgets.QDoubleSpinBox(value=0.9, minimum=0.1, maximum=1.0, singleStep=0.05)
        tol_layout.addRow(self.z_min_label, self.z_min_spin); tol_layout.addRow("Z_max (nm):", self.z_max_spin); tol_layout.addRow("Crop Ratio:", self.crop_ratio_spin)
        control_layout.addWidget(tol_group)
        
        lm_group, lm_layout = create_form_group_box("Local Maxima")
        self.search_size_spin = QtWidgets.QSpinBox(value=3, minimum=3, maximum=21, singleStep=2)
        self.connectivity_combo = QtWidgets.QComboBox(); self.connectivity_combo.addItems(["4", "8"]); self.connectivity_combo.setCurrentText("8")
        lm_layout.addRow("Search Size (nxn):", self.search_size_spin); lm_layout.addRow("Connectivity:", self.connectivity_combo)
        control_layout.addWidget(lm_group)
       
        self.subpix_group, subpix_layout = create_form_group_box("Subpixel Localization", checkable=True)
        self.subpix_scale_spin = QtWidgets.QSpinBox(value=10, minimum=2, maximum=20)
        self.subpix_xy_res_spin = QtWidgets.QDoubleSpinBox(value=0.1, minimum=0.01, maximum=10.0, singleStep=0.01, suffix=" nm")
        self.subpix_z_res_spin = QtWidgets.QDoubleSpinBox(value=0.1, minimum=0.01, maximum=10.0, singleStep=0.01, suffix=" nm")
        subpix_layout.addRow("Scale:", self.subpix_scale_spin); subpix_layout.addRow("XY Resolution:", self.subpix_xy_res_spin); subpix_layout.addRow("Z Resolution:", self.subpix_z_res_spin)
        control_layout.addWidget(self.subpix_group)

        self.sym_group = QtWidgets.QGroupBox("Symmetric Averaging"); self.sym_group.setCheckable(True); self.sym_group.setChecked(False)
        sym_v_layout = QtWidgets.QVBoxLayout(self.sym_group)
        sym_v_layout.setSpacing(5); sym_v_layout.setContentsMargins(8, 10, 8, 8)
        self.sym_prep2_check = QtWidgets.QCheckBox("During Reconstruction (Prep 2)"); self.sym_final_check = QtWidgets.QCheckBox("On Final LAFM Image")
        order_row_layout = QtWidgets.QHBoxLayout()
        order_row_layout.addWidget(QtWidgets.QLabel("Symmetry Order:"))
        self.sym_order_spin = QtWidgets.QSpinBox(value=1, minimum=1, maximum=12)
        order_row_layout.addWidget(self.sym_order_spin); order_row_layout.addStretch()
        sym_v_layout.addWidget(self.sym_prep2_check); sym_v_layout.addWidget(self.sym_final_check); sym_v_layout.addLayout(order_row_layout)
        control_layout.addWidget(self.sym_group)

       
        
        blur_group, blur_layout = create_form_group_box("Gaussian Blur")
        self.blur_sigma_xy_spin = QtWidgets.QDoubleSpinBox(value=1.0, minimum=0.1, maximum=10.0, singleStep=0.1)
        self.blur_sigma_z_spin = QtWidgets.QDoubleSpinBox(value=1.0, minimum=0.1, maximum=10.0, singleStep=0.1)
        blur_layout.addRow("Sigma (xy) [pixels]:", self.blur_sigma_xy_spin); blur_layout.addRow("Sigma (z) [voxels]:", self.blur_sigma_z_spin)
        control_layout.addWidget(blur_group)
        
        # --- â–¼â–¼â–¼ã€é‡è¦è¿½åŠ ã€‘å¯è¦–åŒ–è¨­å®šã®UI â–¼â–¼â–¼ ---
        vis_group, vis_layout = create_form_group_box("Visualization")
        self.vis_delay_spin = QtWidgets.QSpinBox(minimum=0, maximum=1000, value=0, singleStep=10, suffix=" ms")
        vis_layout.addRow("Update Delay (ms):", self.vis_delay_spin)
        control_layout.addWidget(vis_group)
        # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---
        
        self.progress_bar = QtWidgets.QProgressBar()
        control_layout.addWidget(self.progress_bar)
        
        results_group, results_layout = create_form_group_box("Processing Results")
        self.detections_label = QtWidgets.QLabel("0")
        self.reconst_size_label = QtWidgets.QLabel("N/A")
        results_layout.addRow("Total Detections:", self.detections_label); results_layout.addRow("Reconstruction Size:", self.reconst_size_label)
        control_layout.addWidget(results_group)
        
        control_layout.addStretch()

        display_splitter = QtWidgets.QSplitter(QtCore.Qt.Vertical)
        self.top_image_label = QtWidgets.QLabel("Processing View"); self.top_image_label.setMinimumSize(150, 120); self.top_image_label.setAlignment(QtCore.Qt.AlignCenter); self.top_image_label.setStyleSheet("background-color: #111; color: white; border: 1px solid #444;")
        self.bottom_image_label = QtWidgets.QLabel("Final LAFM Image View"); self.bottom_image_label.setMinimumSize(150, 120); self.bottom_image_label.setAlignment(QtCore.Qt.AlignCenter); self.bottom_image_label.setStyleSheet("background-color: black; color: white; border: 1px solid #444;")
        display_splitter.addWidget(self.top_image_label); display_splitter.addWidget(self.bottom_image_label)
        display_splitter.setSizes([150, 150])

        splitter.addWidget(control_widget); splitter.addWidget(display_splitter)
        splitter.setSizes([350, 220])
        main_layout.addWidget(splitter)

        content_widget = QtWidgets.QWidget()
        content_widget.setLayout(main_layout)
        menu_bar = QtWidgets.QMenuBar(self)
        menu_bar.setNativeMenuBar(False)
        help_menu = menu_bar.addMenu("Help")
        manual_action = help_menu.addAction("Manual")
        manual_action.triggered.connect(self.showHelpDialog)
        top_layout = QtWidgets.QVBoxLayout(self)
        top_layout.setContentsMargins(0, 0, 0, 0)
        top_layout.addWidget(menu_bar)
        top_layout.addWidget(content_widget, 1)
        
        self._on_filter_mode_changed(0)
        self._on_z_range_changed()

    def showHelpDialog(self):
        """Help â†’ Manual ã§ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã‚’è¡¨ç¤ºï¼ˆæ—¥æœ¬èª/English åˆ‡æ›¿å¯èƒ½ï¼‰"""
        dialog = QtWidgets.QDialog(self)
        dialog.setMinimumSize(500, 500)
        dialog.resize(600, 650)
        layout_dlg = QtWidgets.QVBoxLayout(dialog)
        lang_row = QtWidgets.QHBoxLayout()
        lang_row.addWidget(QtWidgets.QLabel("Language / è¨€èª:"))
        btn_ja = QtWidgets.QPushButton("æ—¥æœ¬èª", dialog)
        btn_en = QtWidgets.QPushButton("English", dialog)
        btn_ja.setCheckable(True)
        btn_en.setCheckable(True)
        lang_grp = QtWidgets.QButtonGroup(dialog)
        lang_grp.addButton(btn_ja)
        lang_grp.addButton(btn_en)
        lang_grp.setExclusive(True)
        _BTN_SELECTED = "QPushButton { background-color: #007aff; color: white; font-weight: bold; }"
        _BTN_NORMAL = "QPushButton { background-color: #e5e5e5; color: black; }"
        lang_row.addWidget(btn_ja)
        lang_row.addWidget(btn_en)
        lang_row.addStretch()
        layout_dlg.addLayout(lang_row)
        browser = QtWidgets.QTextBrowser(dialog)
        browser.setOpenExternalLinks(True)
        css = """
        body { font-size: 15px; line-height: 1.6; }
        .step { margin: 8px 0; padding: 6px 0; font-size: 15px; }
        .feature-box { margin: 10px 0; padding: 10px; border: 1px solid #ddd; border-radius: 4px; background: #f8f9fa; }
        .note { background-color: #fff3cd; border: 1px solid #ffeaa7; color: #856404; padding: 14px; border-radius: 4px; margin: 14px 0; font-size: 15px; }
        h1 { font-size: 22px; color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }
        h2 { font-size: 18px; color: #2c3e50; margin-top: 18px; }
        h3, h4 { font-size: 16px; color: #34495e; }
        ul { padding-left: 24px; font-size: 15px; }
        table.param-table { border-collapse: collapse; width: 100%; margin: 12px 0; font-size: 14px; }
        table.param-table th, table.param-table td { border: 1px solid #ddd; padding: 10px 12px; text-align: left; }
        table.param-table th { background-color: #f8f9fa; font-weight: bold; }
        """
        browser.document().setDefaultStyleSheet(css)
        close_btn = QtWidgets.QPushButton("Close", dialog)
        close_btn.clicked.connect(dialog.accept)

        def set_lang(use_ja):
            btn_ja.setChecked(use_ja)
            btn_en.setChecked(not use_ja)
            btn_ja.setStyleSheet(_BTN_SELECTED if use_ja else _BTN_NORMAL)
            btn_en.setStyleSheet(_BTN_SELECTED if not use_ja else _BTN_NORMAL)
            if use_ja:
                browser.setHtml("<html><body>" + HELP_HTML_JA.strip() + "</body></html>")
                dialog.setWindowTitle("L-AFMè§£æ - ãƒãƒ‹ãƒ¥ã‚¢ãƒ«")
                close_btn.setText("é–‰ã˜ã‚‹")
            else:
                browser.setHtml("<html><body>" + HELP_HTML_EN.strip() + "</body></html>")
                dialog.setWindowTitle("L-AFM Analysis - Manual")
                close_btn.setText("Close")

        btn_ja.clicked.connect(lambda: set_lang(True))
        btn_en.clicked.connect(lambda: set_lang(False))
        layout_dlg.addWidget(browser)
        layout_dlg.addWidget(close_btn)
        set_lang(False)  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯è‹±èª
        dialog.exec_()

    def closeEvent(self, event):
        """ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒé–‰ã˜ã‚‰ã‚Œã‚‹ã¨ãã«è¨­å®šã‚’ä¿å­˜ã™ã‚‹"""
        try:
            if not hasattr(gv, 'windowSettings'):
                gv.windowSettings = {}
            
            # --- â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘å¤ã„è¨­å®šã‚’å‰Šé™¤ã—ã¦ã‹ã‚‰ã€æ­£ã—ã„ã‚­ãƒ¼ã§ä¿å­˜ã™ã‚‹ â–¼â–¼â–¼ ---
            # ã¾ãšã€"LAFMPanelWindow_1" ã®ã‚ˆã†ãªå¤ã„è¨­å®šãŒã‚ã‚Œã°å‰Šé™¤ã™ã‚‹
            keys_to_delete = [k for k in gv.windowSettings if k.startswith(self.__class__.__name__)]
            for key in keys_to_delete:
                del gv.windowSettings[key]

            # æ¬¡ã«ã€å¸¸ã«ç•ªå·ãªã—ã®æ­£ã—ã„ã‚­ãƒ¼ã§ç¾åœ¨ã®çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹
            gv.windowSettings[self.__class__.__name__] = {
                'x': self.x(), 'y': self.y(),
                'width': self.width(), 'height': self.height(),
                'visible': False,
                'class_name': self.__class__.__name__
            }
            # --- â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–² ---

            if self.main_window and hasattr(self.main_window, 'saveAllInitialParams'):
                self.main_window.saveAllInitialParams()
        
        except Exception as e:
            print(f"[ERROR] Failed to save LAFM panel settings: {e}")
        
        # ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’è§£é™¤ï¼ˆãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã¨ã—ã¦é–‹ã„ã¦ã„ã‚‹å ´åˆï¼‰
        try:
            if hasattr(gv, 'main_window') and gv.main_window and hasattr(gv.main_window, 'plugin_actions'):
                action = gv.main_window.plugin_actions.get(PLUGIN_NAME)
                if action is not None and hasattr(gv.main_window, 'setActionHighlight'):
                    gv.main_window.setActionHighlight(action, False)
        except Exception as e:
            print(f"[WARNING] Failed to reset LAFM action highlight: {e}")
            
        super().closeEvent(event)

    def _collect_params(self):
        self.params = {
            'mode': self.mode_combo.currentText(),
            'filter_mode': self.filter_mode_combo.currentText(),
            'std_dev_factor': self.std_dev_factor_spin.value(),
            'z_min': self.z_min_spin.value(),
            'z_max': self.z_max_spin.value(),
            'crop_ratio': self.crop_ratio_spin.value(),
            'search_size': self.search_size_spin.value(),
            'connectivity': int(self.connectivity_combo.currentText()),
            'subpixel_on': self.subpix_group.isChecked(),
            'subpixel_scale': self.subpix_scale_spin.value(),
            'subpixel_xy_res': self.subpix_xy_res_spin.value(),
            'subpixel_z_res': self.subpix_z_res_spin.value(),
            'sym_on': self.sym_group.isChecked(),
            'sym_on_prep2': self.sym_prep2_check.isChecked(),
            'sym_on_final': self.sym_final_check.isChecked(),
            'sym_order': self.sym_order_spin.value(),
            'blur_sigma_xy': self.blur_sigma_xy_spin.value(),
            'blur_sigma_z': self.blur_sigma_z_spin.value(),
            'drift_correction': self.drift_group.isChecked(),
            'drift_algorithm': self.drift_algorithm_combo.currentText(),
            'drift_threshold': self.drift_threshold_spin.value(),

            'vis_delay_spin': self.vis_delay_spin.value(),
        }
        return self.params

    # â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘_save_lafm_data ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å…¨é¢çš„ã«æ›¸ãæ›ãˆ â–¼â–¼â–¼
    def _save_lafm_data(self):
        """Saveãƒœã‚¿ãƒ³ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚ŒãŸã¨ãã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚¹ãƒ­ãƒƒãƒˆï¼ˆLAFMå°‚ç”¨ä¿å­˜å¯¾å¿œç‰ˆï¼‰"""
        if self.final_lafm_image is None:
            QtWidgets.QMessageBox.warning(self, "No Data", "ä¿å­˜ã™ã‚‹LAFMç”»åƒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return
        
        try:
            base_filename = os.path.splitext(os.path.basename(gv.files[gv.currentFileNum]))[0]
        except:
            base_filename = "LAFM_result"

        if self.params.get('mode', '2D') == '2D':
            default_savename = f"{base_filename}_LAFM.asd"
            file_filter = "ASD File (*.asd)"
        else: # 3D Mode
            default_savename = f"{base_filename}_LAFM_3D.tiff"
            file_filter = "TIFF Image (*.tif *.tiff)"

        if hasattr(gv, 'lastUsedSaveDir') and gv.lastUsedSaveDir and os.path.isdir(gv.lastUsedSaveDir):
            start_folder = gv.lastUsedSaveDir
        else:
            start_folder = os.path.dirname(gv.files[gv.currentFileNum]) if hasattr(gv, 'files') and gv.files else ""
        
        default_save_path = os.path.join(start_folder, default_savename)
        
        filepath, _ = QtWidgets.QFileDialog.getSaveFileName(
            self, "Save LAFM Data", default_save_path, file_filter,
            options=QtWidgets.QFileDialog.DontUseNativeDialog
        )

        if not filepath:
            return

        try:
            self._update_status(f"Saving to {os.path.basename(filepath)}...", color="darkorange")
            
            if self.params['mode'] == '2D':
                # â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘æ–°ã—ãä½œã‚‹å°‚ç”¨ã®ASDä¿å­˜ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã™ â–¼â–¼â–¼
                comment = f"LAFM 2D result from {base_filename}.asd"
                
                # å‡¦ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                from helperFunctions import collect_processing_parameters
                processing_params = collect_processing_parameters()
                if processing_params:
                    comment = comment + "\n" + processing_params
                
                # LAFMå›ºæœ‰ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                lafm_params = []
                if hasattr(self, 'params'):
                    mode = self.params.get('mode', '2D')
                    lafm_params.append(f"Mode: {mode}")
                    if 'z_range' in self.params:
                        z_range = self.params['z_range']
                        lafm_params.append(f"Z Range: {z_range[0]:.1f} - {z_range[1]:.1f} nm")
                    if 'filter_mode' in self.params:
                        lafm_params.append(f"Filter Mode: {self.params['filter_mode']}")
                if lafm_params:
                    comment = comment + "\n[LAFM Parameters]\n" + "\n".join(lafm_params)
                
                success = self._save_lafm_as_asd(filepath, comment, self.final_lafm_image)
                if not success:
                    raise Exception("Failed to save LAFM data as ASD.")
            else:
                tifffile.imsave(filepath, self.final_lafm_image, imagej=True)

            gv.lastUsedSaveDir = os.path.dirname(filepath)
            self._update_status(f"Saved successfully!", color="green")
            QtWidgets.QMessageBox.information(self, "Success", f"LAFMãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ:\n{filepath}")

            if self.main_window and hasattr(self.main_window, 'rescan_and_load'):
                self._update_status(f"Reloading {os.path.basename(filepath)}...", color="info")
                self.main_window.rescan_and_load(filepath)
        
        except Exception as e:
            self._handle_error(f"Failed to save file: {e}")
            import traceback
            traceback.print_exc()

    # (ã“ã‚Œã‚ˆã‚Šä¸‹ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯ã€æ—¢å­˜ã®æ­£ã—ã„ã‚³ãƒ¼ãƒ‰ã‚’ãã®ã¾ã¾å«ã‚ã¦ãã ã•ã„)
    # _collect_params, _update_status, _set_buttons_enabled, _display_image, _handle_error,
    # _update_progress, _run_in_thread, _plot_image, load_initial_data, run_... , _on_..._finished,
    # _on_z_range_changed, _on_filter_mode_changed, _create_lafm_lut, _execute_...
    
        
    def _update_status(self, text, color="blue", level=0):
        self.status_label.setText(text)
        self.status_label.setStyleSheet(f"font-weight: bold; color: {color};")
        #if level == 1: print(f"[LAFM-ERROR] {text}")
        #elif level == 2: print(f"[LAFM-WARN] {text}")
        #else: print(f"[LAFM-INFO] {text}")

    def _set_buttons_enabled(self, prep1, prep2, make_img):
        self.btn_prep1.setEnabled(prep1)
        self.btn_prep2.setEnabled(prep2)
        self.btn_make_img.setEnabled(make_img)


    def _display_image(self, np_array, target='bottom'):
        """
        NumPyé…åˆ—ã‚’ã€æ­£ã—ã„å‘ãã¨ç‰©ç†ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã§UIã®æŒ‡å®šãƒ©ãƒ™ãƒ«ã«è¡¨ç¤ºã™ã‚‹ (FIXED)
        """
        label = self.top_image_label if target == 'top' else self.bottom_image_label

        if np_array is None or np_array.size == 0:
            label.setText("No image to display."); return

        # ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºç”¨ã«ä¸Šä¸‹åè»¢ã•ã›ã‚‹
        display_data = np.flipud(np_array)

        # å†æç”»ç”¨ã«NumPyãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        if target == 'top': self.top_last_np_array = display_data
        else: self.bottom_last_np_array = display_data

        # è¡¨ç¤ºç”¨8-bitã‚«ãƒ©ãƒ¼ç”»åƒã¸å¤‰æ›
        img_to_display = None
        if len(display_data.shape) == 3 and display_data.shape[2] != 3:
            display_data = np.max(display_data, axis=2)
        
        if len(display_data.shape) == 2:
            # â–¼â–¼â–¼ã€ã“ã“ã‹ã‚‰ãŒã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ã®ä¿®æ­£ç®‡æ‰€ã§ã™ã€‘â–¼â–¼â–¼
            
            # self.paramsãŒå­˜åœ¨ã—ã€subpixel_onãŒæœ‰åŠ¹ã‹ãƒã‚§ãƒƒã‚¯
            is_subpixel_mode = self.params.get('subpixel_on', False)

            if is_subpixel_mode:
                # --- ã‚µãƒ–ãƒ”ã‚¯ã‚»ãƒ«ONã®å ´åˆã®å¼·åŠ›ãªå¼·èª¿å‡¦ç† ---
                v_max = np.max(display_data)
                if v_max > 0:
                    scaled_data = display_data.astype(np.float32) / v_max
                    gamma = 0.3  # å¼·ã„ã‚¬ãƒ³ãƒè£œæ­£
                    gamma_corrected = np.power(scaled_data, gamma)
                    img_norm_8u = (gamma_corrected * 255).astype(np.uint8)
                else:
                    img_norm_8u = np.zeros_like(display_data, dtype=np.uint8)
            else:
                # --- é€šå¸¸æ™‚ã®ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ (éã‚¼ãƒ­ãƒ”ã‚¯ã‚»ãƒ«ã®ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«) ---
                non_zero_pixels = display_data[display_data > 0]
                if non_zero_pixels.size > 0:
                    v_min, v_max = np.percentile(non_zero_pixels, (1, 99))
                    if v_max <= v_min:
                        v_min, v_max = np.min(non_zero_pixels), np.max(non_zero_pixels)
                    clipped_data = np.clip(display_data, v_min, v_max)
                    scale = 255.0 / (v_max - v_min) if (v_max - v_min) > 0 else 0
                    img_norm_8u = ((clipped_data - v_min) * scale).astype(np.uint8)
                else:
                    img_norm_8u = np.zeros_like(display_data, dtype=np.uint8)

            # å…±é€šã®ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—é©ç”¨
            img_to_display = cv2.applyColorMap(img_norm_8u, self._create_lafm_lut())
            # â–²â–²â–²ã€ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆèª¿æ•´ã®ä¿®æ­£ã“ã“ã¾ã§ã€‘â–²â–²â–²
       
        elif len(display_data.shape) == 3 and display_data.shape[2] == 3:
            img_to_display = display_data.astype(np.uint8)

        if img_to_display is None: return

        # QPixmapã«å¤‰æ›
        h_px, w_px, ch = img_to_display.shape
        q_img = QtGui.QImage(img_to_display.data, w_px, h_px, ch * w_px, QtGui.QImage.Format_RGB888).rgbSwapped()
        pixmap = QtGui.QPixmap.fromImage(q_img)
        
        if target == 'top': self.top_current_pixmap = pixmap
        else: self.bottom_current_pixmap = pixmap

        # --- â–¼â–¼â–¼ ã“ã“ã‹ã‚‰ãŒä¿®æ­£ç®‡æ‰€ â–¼â–¼â–¼ ---
        aspect_ratio = 1.0
        
        if target == 'bottom' and hasattr(self, 'lafm_image_scan_size'):
            # ä¸‹éƒ¨ãƒ“ãƒ¥ãƒ¼ã‚¢ã®å ´åˆ: å†æ§‹æˆå¾Œã®ç”»åƒã®ç‰©ç†ã‚µã‚¤ã‚ºã‹ã‚‰ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
            scan_size = self.lafm_image_scan_size
            if scan_size.get('y', 0) > 0:
                aspect_ratio = scan_size['x'] / scan_size['y']
        elif hasattr(self, 'scale_info'):
            # ä¸Šéƒ¨ãƒ“ãƒ¥ãƒ¼ã‚¢ã®å ´åˆ: å…ƒç”»åƒã®ãƒ”ã‚¯ã‚»ãƒ«ã‚ãŸã‚Šã®ç‰©ç†ã‚µã‚¤ã‚ºã‹ã‚‰ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨ˆç®—
            dx = self.scale_info.get('dx', 1.0)
            dy = self.scale_info.get('dy', 1.0)
            if dy > 0:
                # ç‰©ç†ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” = (ç‰©ç†çš„ãªå¹…) / (ç‰©ç†çš„ãªé«˜ã•) = (ãƒ”ã‚¯ã‚»ãƒ«å¹… * dx) / (ãƒ”ã‚¯ã‚»ãƒ«é«˜ * dy)
                aspect_ratio = (w_px * dx) / (h_px * dy)
        
        # ãƒªã‚µã‚¤ã‚ºç”¨ã«ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’è¨˜æ†¶
        if target == 'top': self.top_last_aspect_ratio = aspect_ratio
        else: self.bottom_last_aspect_ratio = aspect_ratio
        # --- â–²â–²â–² ä¿®æ­£ã“ã“ã¾ã§ â–²â–²â–² ---

        # ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”ã‚’ç¶­æŒã—ã¦ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ï¼†è¡¨ç¤º
        widget_size = label.size()
        if widget_size.isEmpty(): return
        
        display_width = widget_size.width()
        display_height = int(display_width / aspect_ratio) if aspect_ratio > 0 else 0
        if display_height > widget_size.height():
            display_height = widget_size.height()
            display_width = int(display_height * aspect_ratio)
            
        display_size = QtCore.QSize(display_width, display_height)
        scaled_pixmap = pixmap.scaled(display_size, QtCore.Qt.IgnoreAspectRatio, QtCore.Qt.SmoothTransformation)
        label.setPixmap(scaled_pixmap)

    def _handle_error(self, message):
        self._update_status(f"Error: {message.splitlines()[0]}", color="red", level=1)
        QtWidgets.QMessageBox.critical(self, "Processing Error", message)
        self._set_buttons_enabled(True, False, False)
        self.btn_prep2.setEnabled(self.detection_summary is not None)
        self.btn_make_img.setEnabled(self.reconstruction is not None)
        self.btn_save.setEnabled(self.final_lafm_image is not None)

    def _update_progress(self, value, message):
        self.progress_bar.setValue(value)
        self._update_status(message, color="darkorange")

    def _run_in_thread(self, function, on_finish, *args, **kwargs):
        self._set_buttons_enabled(False, False, False)
        self.btn_save.setEnabled(False) # å‡¦ç†ä¸­ã¯Saveãƒœã‚¿ãƒ³ã‚‚ç„¡åŠ¹åŒ–
        self.thread = QtCore.QThread()
        self.worker = LAFMWorker(function, *args, **kwargs)
        self.worker.moveToThread(self.thread)
        self.worker.progress.connect(self._update_progress)
        self.worker.error.connect(self._handle_error)
        self.worker.plot_signal.connect(self._plot_image)
        self.worker.finished.connect(on_finish)
        self.worker.finished.connect(self.thread.quit)
        self.worker.finished.connect(self.worker.deleteLater)
        self.thread.finished.connect(self.thread.deleteLater)
        self.thread.started.connect(self.worker.run)
        self.thread.start()

    def _plot_image(self, image_data, target_name):
        """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã‹ã‚‰ã®æç”»ã‚·ã‚°ãƒŠãƒ«ã‚’å‡¦ç†ã™ã‚‹ã‚¹ãƒ­ãƒƒãƒˆ"""
        self._display_image(image_data, target=target_name)
  

    def load_initial_data(self, progress_signal=None, plot_signal=None):
        if self.main_window:
            start_frame = gv.FirstFrame if gv.FirstFrame is not None else 0
            end_frame = gv.LastFrame if gv.LastFrame is not None else gv.FrameNum - 1
            
            # get_image_stack_for_lafmã‚‚ãƒ•ãƒ¬ãƒ¼ãƒ ã”ã¨ã«ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ã‚’å ±å‘Šã™ã‚‹ã‚ˆã†ã«å¤‰æ›´ãŒå¿…è¦ã§ã™ãŒã€
            # ã¾ãšã¯ã“ã¡ã‚‰ã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’ä¿®æ­£ã—ã¾ã™ã€‚
            stack, scale_info = self.main_window.get_image_stack_for_lafm(start_frame, end_frame)
            
            # ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã¯å€¤ã‚’è¿”ã—ã€ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°ã¯ç›´æ¥è¨­å®šã—ãªã„
            return stack, scale_info
        return None, None

    def run_preprocessing1(self):
        # â–¼â–¼â–¼ã€ã“ã®ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ã‚·ãƒ³ãƒ—ãƒ«ã«æ›¸ãæ›ãˆã¦ãã ã•ã„ã€‘â–¼â–¼â–¼

        # Preprocessing1ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸéš›ã«ã€ä»¥å‰ã®çµæœã‚’ã‚¯ãƒªã‚¢ã™ã‚‹
        if self.main_window:
            start_frame = gv.FirstFrame if gv.FirstFrame is not None else 0
            end_frame = gv.LastFrame if gv.LastFrame is not None else gv.FrameNum - 1
            stack, scale_info = self.main_window.get_image_stack_for_lafm(start_frame, end_frame)
            
            if stack is not None:
                self.original_image_stack = stack
                self.scale_info = scale_info
                # ä»¥å‰ã®çµæœã‚’ã‚¯ãƒªã‚¢
                self.detection_summary = None
                self.reconstruction = None
                self.reconstruction_image = None
                self.final_lafm_image = None
                # UIã®çŠ¶æ…‹ã‚’æ›´æ–°
                self.detections_label.setText("0")
                self.reconst_size_label.setText("N/A")
                self._display_image(self.original_image_stack[:, :, 0], target='bottom')
            else:
                self._update_status("Failed to load current file data.", color="red")
                return
                
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’åé›†ã—ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰ã§ _execute_preprocessing1 ã‚’å®Ÿè¡Œ
        self._collect_params()
        self._update_status("Step 1: Cropping and correcting...", color="darkorange")
        self.btn_save.setEnabled(False)
        self.progress_bar.setRange(0, 100)
        self._run_in_thread(self._execute_preprocessing1, self._on_preprocessing1_finished, self.original_image_stack, self.params)

    def _on_drift_correction_finished(self, result):
        """ãƒ‰ãƒªãƒ•ãƒˆè£œæ­£å®Œäº†å¾Œã«preprocessing1ã‚’é–‹å§‹"""
        if result is not None:
            corrected_stack, excluded_frames = result
            self.original_image_stack = corrected_stack
            
            if len(excluded_frames) > 0:
                self._update_status(f"Drift correction excluded {len(excluded_frames)} frames. Starting detection...", color="info")
            else:
                self._update_status("Drift correction completed. Starting detection...", color="info")
        else:
            self._update_status("Drift correction failed. Using original data...", color="warning")
        
        # ãƒ‰ãƒªãƒ•ãƒˆè£œæ­£å¾Œã¯æ—¢å­˜ã¨åŒã˜preprocessing1ã‚’å®Ÿè¡Œ
        self._collect_params()
        self._update_status("Step 1: Detecting local maxima...", color="darkorange")
        self.btn_save.setEnabled(False)
        self.progress_bar.setRange(0, 100)
        self._run_in_thread(self._execute_preprocessing1, self._on_preprocessing1_finished, self.original_image_stack, self.params)
        
    # def _execute_drift_correction(self, image_stack, params, progress_signal=None, plot_signal=None):
    #     """ãƒ‰ãƒªãƒ•ãƒˆè£œæ­£ã‚’å®Ÿè¡Œï¼ˆaveraging.pyã®ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ´»ç”¨ï¼‰"""
    #     print(f"[DEBUG] _execute_drift_correction called with stack shape: {image_stack.shape}")
    #     print(f"[DEBUG] Drift params: {params}")

    #     try:
    #         if progress_signal: progress_signal.emit(10, "Calculating transformations...")
            
    #         is_feature_based = "Feature-based" in params['drift_algorithm']
    #         confidence_threshold = params['drift_threshold']
            
    #         # å¤‰æ›è¡Œåˆ—ã¨ä¿¡é ¼åº¦ã‚’è¨ˆç®—
    #         matrices, confidences = self._calculate_transformations_for_lafm(
    #             image_stack, 
    #             is_rotation_enabled=is_feature_based,
    #             progress_signal=progress_signal
    #         )
            
    #         if progress_signal: progress_signal.emit(50, "Filtering unreliable frames...")
            
    #         # ä¿¡é ¼åº¦ã«ã‚ˆã‚‹é™¤å¤–
    #         good_indices = np.where(confidences > confidence_threshold)[0]
    #         excluded_frames = [i for i in range(len(image_stack)) if i not in good_indices]
            
    #         if len(good_indices) < 2:
    #             if progress_signal: progress_signal.emit(100, "Drift correction failed - insufficient reliable frames")
    #             return None
            
    #         if progress_signal: progress_signal.emit(80, "Applying transformations...")
            
    #         # è£œæ­£æ¸ˆã¿ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‚’ä½œæˆ
    #         corrected_stack = image_stack[good_indices]
    #         matrices_to_apply = matrices[good_indices]
    #         h, w = corrected_stack[0].shape
            
    #         # å„ç”»åƒã«å¤‰æ›è¡Œåˆ—ã‚’é©ç”¨
    #         final_corrected_stack = np.array([
    #             cv2.warpAffine(img, M, (w, h), borderValue=np.median(img)) 
    #             for img, M in zip(corrected_stack, matrices_to_apply)
    #         ])
            
    #         if progress_signal: progress_signal.emit(100, "Drift correction completed")
            
    #         return final_corrected_stack, excluded_frames
            
    #     except Exception as e:
    #         if progress_signal: progress_signal.emit(100, f"Drift correction error: {e}")
    #         return None
    # å®Œå…¨ãª_execute_drift_correction_syncãƒ¡ã‚½ãƒƒãƒ‰

    

    def _calculate_feature_based_real(self, image_stack, progress_dialog):
        """AFMç”»åƒã«æœ€é©åŒ–ã•ã‚ŒãŸFeature-basedå‡¦ç†"""
        num_images = len(image_stack)
        total_matrices = [np.eye(2, 3, dtype=np.float32) for _ in range(num_images)]
        confidences = np.ones(num_images)
        
        # å›ºå®šãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼‰
        reference_image = image_stack[0]
        
        #print(f"[DEBUG] AFM-optimized Feature-based processing")
        #print(f"[DEBUG] Reference image: shape={reference_image.shape}")
        
        # AFMç”¨ã«èª¿æ•´ã•ã‚ŒãŸORBè¨­å®š
        orb = cv2.ORB_create(
            nfeatures=1000,      # ç‰¹å¾´ç‚¹æ•°ã‚’åˆ¶é™ï¼ˆè³ªã‚’é‡è¦–ï¼‰
            scaleFactor=1.2,     # ã‚ˆã‚Šç²—ã„ã‚¹ã‚±ãƒ¼ãƒ«
            nlevels=8,           # ãƒ¬ãƒ™ãƒ«æ•°ã‚’æ¸›ã‚‰ã™
            edgeThreshold=10,    # ã‚¨ãƒƒã‚¸é–¾å€¤ã‚’ä¸Šã’ã‚‹ï¼ˆãƒã‚¤ã‚ºé™¤å»ï¼‰
            firstLevel=0,
            WTA_K=2,
            scoreType=cv2.ORB_HARRIS_SCORE,
            patchSize=31,
            fastThreshold=10     # é–¾å€¤ã‚’ä¸Šã’ã¦å“è³ªé‡è¦–
        )
        
        # å‚ç…§ç”»åƒã®ç‰¹å¾´ç‚¹ã‚’äº‹å‰è¨ˆç®—
        ref_enhanced = self._enhance_for_afm_features(reference_image)
        kp_ref, des_ref = orb.detectAndCompute(ref_enhanced, None)
        
        #print(f"[DEBUG] Reference features: {len(kp_ref) if kp_ref else 0} keypoints")
        
        for i in range(1, min(num_images, 11)):  # æœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ãƒ†ã‚¹ãƒˆ
            current_image = image_stack[i]
            transformation_matrix = np.eye(2, 3, dtype=np.float32)
            confidence = 0.0
            
            try:
                # ç¾åœ¨ãƒ•ãƒ¬ãƒ¼ãƒ ã®å‰å‡¦ç†ã¨ç‰¹å¾´ç‚¹æ¤œå‡º
                curr_enhanced = self._enhance_for_afm_features(current_image)
                kp_curr, des_curr = orb.detectAndCompute(curr_enhanced, None)

                #print(f"\n[DEBUG] Frame {i}:")
                #print(f"  Features: {len(kp_curr) if kp_curr else 0} keypoints")
                
                if des_curr is not None and des_ref is not None and len(des_ref) > 20 and len(des_curr) > 20:
                    # ã‚ˆã‚Šå³å¯†ãªãƒãƒƒãƒãƒ³ã‚°
                    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
                    matches = matcher.match(des_ref, des_curr)
                    
                    if len(matches) > 20:  # æœ€ä½ãƒãƒƒãƒæ•°ã‚’å¢—ã‚„ã™
                        matches = sorted(matches, key=lambda x: x.distance)
                        
                        # ã‚ˆã‚Šå³ã—ã„è·é›¢ãƒ•ã‚£ãƒ«ã‚¿
                        distance_threshold = min(60, matches[0].distance * 2.0)  # ã‚ˆã‚Šå³ã—ã„
                        good_matches = [m for m in matches if m.distance < distance_threshold]
                        
                        #print(f"  Matches: {len(matches)} â†’ {len(good_matches)} (thresh={distance_threshold})")
                        
                        if len(good_matches) >= 8:  # æœ€ä½ç‚¹æ•°ã‚’å¢—ã‚„ã™
                            ref_pts = np.float32([kp_ref[m.queryIdx].pt for m in good_matches])
                            curr_pts = np.float32([kp_curr[m.trainIdx].pt for m in good_matches])
                            
                            # ç‚¹ã®åˆ†å¸ƒã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆæ¥µç«¯ã«åã£ã¦ã„ãªã„ã‹ï¼‰
                            ref_spread = np.std(ref_pts, axis=0)
                            curr_spread = np.std(curr_pts, axis=0)
                            min_spread = min(reference_image.shape) * 0.1  # ç”»åƒã®10%ä»¥ä¸Šã«åˆ†å¸ƒ
                            
                            if np.min(ref_spread) > min_spread and np.min(curr_spread) > min_spread:
                                # ã‚ˆã‚Šå³å¯†ãªRANSACè¨­å®š
                                try:
                                    M_cv = cv2.estimateAffinePartial2D(
                                        curr_pts, ref_pts,
                                        method=cv2.RANSAC,
                                        ransacReprojThreshold=2.0,  # ã‚ˆã‚Šå³ã—ã„é–¾å€¤
                                        maxIters=5000,
                                        confidence=0.99,            # é«˜ã„ä¿¡é ¼åº¦è¦æ±‚
                                        refineIters=10
                                    )
                                    
                                    if M_cv[0] is not None and M_cv[1] is not None:
                                        matrix = M_cv[0]
                                        inliers = M_cv[1].flatten()
                                        inlier_count = np.sum(inliers)
                                        inlier_ratio = inlier_count / len(good_matches)
                                        
                                        # å¤‰æ›ã®å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆAFMç”¨ã®å³ã—ã„åˆ¶é™ï¼‰
                                        translation = np.linalg.norm(matrix[:, 2])
                                        angle = np.arctan2(matrix[1, 0], matrix[0, 0])
                                        scale_x = np.sqrt(matrix[0,0]**2 + matrix[0,1]**2)
                                        scale_y = np.sqrt(matrix[1,0]**2 + matrix[1,1]**2)
                                        
                                        #print(f"  Transform: trans={translation:.1f}px, angle={np.degrees(angle):.1f}Â°")
                                        #print(f"  Scale: ({scale_x:.3f}, {scale_y:.3f}), inliers: {inlier_count}/{len(good_matches)} ({inlier_ratio:.3f})")
                                        
                                        # AFMç”¨ã®å³ã—ã„åˆ¶é™
                                        max_translation = min(current_image.shape) * 0.2  # 20%ã¾ã§
                                        max_angle = np.pi / 12  # Â±15åº¦ã¾ã§
                                        
                                        if (translation < max_translation and 
                                            abs(angle) < max_angle and
                                            0.98 <= scale_x <= 1.02 and    # ã»ã¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰åŒ–ãªã—
                                            0.98 <= scale_y <= 1.02 and
                                            inlier_ratio > 0.5 and         # 50%ä»¥ä¸Šã®ã‚¤ãƒ³ãƒ©ã‚¤ã‚¢
                                            inlier_count >= 10):           # æœ€ä½10ç‚¹ã®ã‚¤ãƒ³ãƒ©ã‚¤ã‚¢
                                            
                                            transformation_matrix = matrix
                                            confidence = inlier_ratio * min(1.0, inlier_count / 20.0)
                                            
                                            #print(f"  âœ… ACCEPTED - confidence: {confidence:.3f}")
                                        else:
                                            confidence = 0.05
                                            #print(f"  âŒ REJECTED - strict AFM limits")
                                            #print(f"    Limits: trans<{max_translation:.1f}, angle<{np.degrees(max_angle):.1f}Â°, inlier>{0.5}")
                                    else:
                                        confidence = 0.02
                                        #print(f"  âŒ RANSAC failed")
                                        
                                except Exception as e:
                                    confidence = 0.01
                                    #print(f"  âŒ Exception: {e}")
                            else:
                                confidence = 0.02
                                #print(f"  âŒ Poor point distribution: {ref_spread}, {curr_spread}")
                        else:
                            confidence = 0.02
                            #print(f"  âŒ Too few good matches: {len(good_matches)}")
                    else:
                        confidence = 0.01
                        #print(f"  âŒ Insufficient total matches: {len(matches)}")
                else:
                    confidence = 0.01
                    #print(f"  âŒ Too few features")
                        
            except Exception as e:
                confidence = 0.01
                print(f"  âŒ Exception: {e}")

            confidences[i] = confidence
            total_matrices[i] = transformation_matrix
            
            # æ®‹ã‚Šã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯ä½ä¿¡é ¼åº¦ã‚’å‰²ã‚Šå½“ã¦
            for j in range(max(11, i+1), num_images):
                confidences[j] = 0.05
        
        #print(f"\n[DEBUG] AFM Feature-based summary:")
        #print(f"  Confidence range: {np.min(confidences):.4f} - {np.max(confidences):.4f}")
        #print(f"  Frames > 0.1: {np.sum(confidences > 0.1)}/{len(confidences)}")
        #print(f"  Frames > 0.5: {np.sum(confidences > 0.5)}/{len(confidences)}")
            
        return np.array(total_matrices), confidences

    def _enhance_for_afm_features(self, image):
        """AFMç”»åƒå°‚ç”¨ã®ç‰¹å¾´ç‚¹å¼·èª¿"""
        # 8bitå¤‰æ›
        img = cv2.normalize(image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
        
        # AFMç”»åƒã®ç‰¹å¾´ã‚’å¼·èª¿
        # 1. è»½ã„ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ–ãƒ©ãƒ¼ã§ãƒã‚¤ã‚ºé™¤å»
        denoised = cv2.GaussianBlur(img, (3, 3), 0.8)
        
        # 2. é©å¿œãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ å‡ç­‰åŒ–ï¼ˆæ§ãˆã‚ï¼‰
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(4,4))
        enhanced = clahe.apply(denoised)
        
        # 3. è»½ã„ã‚¨ãƒƒã‚¸å¼·èª¿
        kernel = np.array([[-0.05, -0.1, -0.05],
                        [-0.1,   1.3, -0.1],
                        [-0.05, -0.1, -0.05]])
        sharpened = cv2.filter2D(enhanced, -1, kernel)
        
        return np.clip(sharpened, 0, 255).astype(np.uint8)

    def _calculate_rigid_transformation_simple(self, prev_pts, curr_pts):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªå‰›ä½“å¤‰æ›è¨ˆç®—ï¼ˆRANSACãƒ™ãƒ¼ã‚¹ï¼‰"""
        if len(prev_pts) < 6:
            return None, None, 0.0
        
        try:
            # RANSACã«ã‚ˆã‚‹å¤–ã‚Œå€¤é™¤å»
            best_inliers = None
            best_matrix = None
            max_inliers = 0
            
            n_iterations = min(100, len(prev_pts) * 2)
            threshold = 4.0
            
            for iteration in range(n_iterations):
                # æœ€å°6ç‚¹ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
                indices = np.random.choice(len(prev_pts), 6, replace=False)
                sample_prev = prev_pts[indices]
                sample_curr = curr_pts[indices]
                
                # ç°¡æ˜“å‰›ä½“å¤‰æ›æ¨å®š
                matrix = self._estimate_rigid_simple(sample_prev, sample_curr)
                
                if matrix is not None:
                    # å…¨ç‚¹ã§ã®èª¤å·®è¨ˆç®—
                    prev_pts_hom = np.column_stack([prev_pts, np.ones(len(prev_pts))])
                    transformed_pts = (matrix @ prev_pts_hom.T).T
                    
                    errors = np.linalg.norm(transformed_pts - curr_pts, axis=1)
                    inliers = errors < threshold
                    n_inliers = np.sum(inliers)
                    
                    if n_inliers > max_inliers:
                        max_inliers = n_inliers
                        best_inliers = inliers
                        best_matrix = matrix
            
            if best_matrix is not None and max_inliers >= 6:
                # å†…ç‚¹ã®ã¿ã§å†æ¨å®š
                inlier_prev = prev_pts[best_inliers]
                inlier_curr = curr_pts[best_inliers]
                
                refined_matrix = self._estimate_rigid_simple(inlier_prev, inlier_curr)
                
                if refined_matrix is not None:
                    inlier_ratio = max_inliers / len(prev_pts)
                    return refined_matrix, best_inliers, inlier_ratio
            
            return None, None, 0.0
            
        except Exception as e:
            return None, None, 0.0

    def _estimate_rigid_simple(self, src_pts, dst_pts):
        """ç°¡æ˜“å‰›ä½“å¤‰æ›æ¨å®šï¼ˆé‡å¿ƒãƒ™ãƒ¼ã‚¹ï¼‰"""
        try:
            if len(src_pts) < 3 or len(dst_pts) < 3:
                return None
            
            # é‡å¿ƒã‚’è¨ˆç®—
            src_center = np.mean(src_pts, axis=0)
            dst_center = np.mean(dst_pts, axis=0)
            
            # é‡å¿ƒã‹ã‚‰ã®ç›¸å¯¾ä½ç½®
            src_centered = src_pts - src_center
            dst_centered = dst_pts - dst_center
            
            # å›è»¢è§’åº¦æ¨å®šï¼ˆæœ€å°äºŒä¹—æ³•ï¼‰
            angles = []
            for i in range(min(len(src_centered), 10)):
                if np.linalg.norm(src_centered[i]) > 1e-6 and np.linalg.norm(dst_centered[i]) > 1e-6:
                    angle_src = np.arctan2(src_centered[i][1], src_centered[i][0])
                    angle_dst = np.arctan2(dst_centered[i][1], dst_centered[i][0])
                    angle_diff = angle_dst - angle_src
                    # è§’åº¦ã‚’[-Ï€, Ï€]ã«æ­£è¦åŒ–
                    angle_diff = np.arctan2(np.sin(angle_diff), np.cos(angle_diff))
                    angles.append(angle_diff)
            
            if len(angles) == 0:
                angle = 0.0
            else:
                # å¹³å‡è§’åº¦ã‚’è¨ˆç®—ï¼ˆå††å½¢å¹³å‡ï¼‰
                angle = np.arctan2(np.mean(np.sin(angles)), np.mean(np.cos(angles)))
            
            # è§’åº¦åˆ¶é™ï¼ˆÂ±45åº¦ä»¥å†…ï¼‰
            if abs(angle) > np.pi/4:
                return None
            
            # å›è»¢è¡Œåˆ—ä½œæˆ
            cos_a, sin_a = np.cos(angle), np.sin(angle)
            
            # å¹³è¡Œç§»å‹•ãƒ™ã‚¯ãƒˆãƒ«ï¼ˆé‡å¿ƒã®ç§»å‹•ï¼‰
            tx = dst_center[0] - src_center[0]
            ty = dst_center[1] - src_center[1]
            
            # å¹³è¡Œç§»å‹•åˆ¶é™ï¼ˆÂ±100ãƒ”ã‚¯ã‚»ãƒ«ä»¥å†…ï¼‰
            if abs(tx) > 100 or abs(ty) > 100:
                return None
            
            # å¤‰æ›è¡Œåˆ—æ§‹ç¯‰
            matrix = np.array([
                [cos_a, -sin_a, tx],
                [sin_a,  cos_a, ty]
            ], dtype=np.float32)
            
            return matrix
                
        except Exception as e:
            return None
    
    def _calculate_simple_fallback(self, image_stack, progress_dialog):
        """æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†"""
        num_images = len(image_stack)
        matrices = [np.eye(2, 3, dtype=np.float32) for _ in range(num_images)]
        confidences = np.ones(num_images) * 0.5  # å…¨ãƒ•ãƒ¬ãƒ¼ãƒ ã«0.5ã®ä¿¡é ¼åº¦ã‚’ä¸ãˆã‚‹
        
        #print(f"[DEBUG] Using simple fallback - all frames get confidence 0.5")
        
        return np.array(matrices), confidences

        
    def _calculate_phase_correlation_simple(self, image_stack, progress_dialog):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªPhase Correlationè¨ˆç®—"""
        num_images = len(image_stack)
        matrices = [np.eye(2, 3, dtype=np.float32) for _ in range(num_images)]
        confidences = np.ones(num_images)
        
        # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’åŸºæº–ã¨ã™ã‚‹
        reference_image = image_stack[0]
        
        for i in range(1, num_images):
            if progress_dialog.wasCanceled():
                return None, None
                
            if i % 10 == 0:
                progress = int(10 + 50 * i / num_images)
                progress_dialog.setValue(progress)
                progress_dialog.setLabelText(f"Processing frame {i}/{num_images}")
                QtWidgets.QApplication.processEvents()
            
            current_image = image_stack[i]
            
            try:
                # å‰å‡¦ç†
                ref_processed = self._preprocess_for_correlation(reference_image)
                curr_processed = self._preprocess_for_correlation(current_image)
                
                # Phase Correlation
                shift, error, _ = phase_cross_correlation(
                    ref_processed, curr_processed, 
                    upsample_factor=2,
                    space="real"
                )
                
                # ä¿¡é ¼åº¦è¨ˆç®—
                max_allowed_shift = min(current_image.shape) * 0.2
                shift_magnitude = np.linalg.norm(shift)
                
                if error < 0.5 and shift_magnitude < max_allowed_shift:
                    confidence = max(0.1, min(1.0, (0.5 - error) * 2.0))
                    matrices[i][0, 2] = shift[1]  # dx
                    matrices[i][1, 2] = shift[0]  # dy
                else:
                    confidence = 0.01
                    
                confidences[i] = confidence
                
            except Exception as e:
                #print(f"[DEBUG] Frame {i} failed: {e}")
                confidences[i] = 0.01
        
        return np.array(matrices), confidences

    def _enhance_vertical_features(self, image):
        """å‚ç›´æ–¹å‘ã®ç‰¹å¾´ã‚’å¼·èª¿ã™ã‚‹å‰å‡¦ç†ï¼ˆaveraging.pyã¨åŒã˜ï¼‰"""
        # Sobelãƒ•ã‚£ãƒ«ã‚¿ã§å‚ç›´ã‚¨ãƒƒã‚¸ã‚’å¼·èª¿
        sobel_x = cv2.Sobel(image.astype(np.float32), cv2.CV_32F, 1, 0, ksize=3)
        
        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ•ã‚£ãƒ«ã‚¿ã§ãƒã‚¤ã‚ºé™¤å»
        enhanced = cv2.GaussianBlur(np.abs(sobel_x), (1, 5), 0)  # å‚ç›´æ–¹å‘ã«ã®ã¿ãƒ–ãƒ©ãƒ¼
        
        # æ­£è¦åŒ–
        enhanced = cv2.normalize(enhanced, None, 0.0, 1.0, cv2.NORM_MINMAX)
        
        return enhanced# ã‚¹ãƒ¬ãƒƒãƒ‰ã‚’ä½¿ã‚ãªã„ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‰ãƒªãƒ•ãƒˆè£œæ­£ç‰ˆ


    def _calculate_feature_based_simple(self, image_stack, progress_dialog):
        """ã‚·ãƒ³ãƒ—ãƒ«ãªFeature-basedè¨ˆç®—ï¼ˆã¨ã‚Šã‚ãˆãšPhase Correlationã¨åŒã˜ï¼‰"""
        # ã¨ã‚Šã‚ãˆãšPhase Correlationã¨åŒã˜å‡¦ç†
        return self._calculate_phase_correlation_simple(image_stack, progress_dialog)

    def _preprocess_for_correlation(self, image):
        """ä½ç›¸ç›¸é–¢ã®ãŸã‚ã®ç”»åƒå‰å‡¦ç†"""
        img = image.astype(np.float32)
        img = cv2.GaussianBlur(img, (3, 3), 0.5)
        img = cv2.normalize(img, None, 0.0, 1.0, cv2.NORM_MINMAX)
        return img

    
    def _on_preprocessing1_finished(self, result):
        if result is not None:
            detections, processed_stack = result
            if detections is not None and len(detections) > 0:
                self.detection_summary = detections
                self.processed_image_stack = processed_stack # æ–°ã—ã„ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‚’ä¿å­˜
                
                self.detections_label.setText(str(len(detections)))
                self._update_status("Step 1: Preprocessing 1 finished.", color="green")
                self._set_buttons_enabled(True, True, False)
            else:
                self._handle_error("No peaks detected with current parameters.")

    def run_preprocessing2(self):
        self._collect_params()
        self._update_status("Step 2: Reconstructing...", color="darkorange")
        self.btn_save.setEnabled(False)
        self.progress_bar.setRange(0, 100)
        self._run_in_thread(
            self._execute_preprocessing2, 
            self._on_preprocessing2_finished, 
            self.detection_summary, 
            self.processed_image_stack, # å…ƒç”»åƒã®shapeã§ã¯ãªãã€æ–°ã—ã„ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ãã®ã‚‚ã®ã‚’æ¸¡ã™
            self.params
        )

    def _on_preprocessing2_finished(self, results):
        if results is not None:
            # æ‰‹é †1ã§è¿½åŠ ã—ãŸæˆ»ã‚Šå€¤ã‚’å—ã‘å–ã‚‹ã‚ˆã†ã«ã‚¢ãƒ³ãƒ‘ãƒƒã‚¯å‡¦ç†ã‚’ä¿®æ­£ã—ã¾ã™ã€‚
            self.reconstruction, self.reconstruction_image, self.reconst_scan_size = results

            # è¡¨ç¤ºç”¨ã®ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”è¨ˆç®—ã®ãŸã‚ã«ã€å—ã‘å–ã£ãŸç‰©ç†ã‚µã‚¤ã‚ºã‚’display_image_scan_sizeã«è¨­å®šã—ã¾ã™ã€‚
            # ã“ã‚Œã«ã‚ˆã‚Šã€é–“é•ã£ãŸç‰©ç†ã‚µã‚¤ã‚ºã®å†è¨ˆç®—ãŒä¸è¦ã«ãªã‚Šã¾ã™ã€‚
            self.display_image_scan_size = self.reconst_scan_size
 
            self.reconst_size_label.setText(f"{self.reconstruction.shape[0]} x {self.reconstruction.shape[1]}")
            self._update_status("Step 2: Reconstruction finished.", color="green")
            self._set_buttons_enabled(True, True, True)
            if self.params.get('mode', '2D') == '2D':
                display_img = np.sum(self.reconstruction, axis=2)
            else:
                display_img = np.max(self.reconstruction, axis=2)
            self._display_image(display_img, target='bottom')

    def run_make_lafm_image(self):
        self._collect_params()
        self._update_status("Step 3: Making final LAFM image...", color="darkorange")
        self.btn_save.setEnabled(False)
        self.progress_bar.setRange(0, 100)
        self._run_in_thread(self._execute_make_lafm_image, self._on_make_lafm_image_finished, self.reconstruction, self.reconstruction_image, self.params)
        
    def _on_make_lafm_image_finished(self, result):
        if result is not None:
            self.final_lafm_image = result

             # ä¿å­˜ã¨è¡¨ç¤ºã§ä½¿ã†ãŸã‚ã«ã€æœ€çµ‚ç”»åƒã®ç‰©ç†ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã¦ä¿å­˜ã™ã‚‹
            try:
                # Preprocessing 2ã§è¨ˆç®—ãƒ»ä¿å­˜ã—ãŸæ­£ã—ã„ç‰©ç†ã‚µã‚¤ã‚ºã‚’ã“ã“ã§ä½¿ã„ã¾ã™ã€‚
                if hasattr(self, 'reconst_scan_size') and self.reconst_scan_size is not None:
                    self.lafm_image_scan_size = self.reconst_scan_size
                    final_phys_w = self.lafm_image_scan_size['x']
                    final_phys_h = self.lafm_image_scan_size['y']
            
                else:
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆé€šå¸¸ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ï¼‰
                    raise ValueError("Reconstructed scan size not found.")

            except Exception as e:
                print(f"[ERROR] Could not set final image physical size: {e}")
                self.lafm_image_scan_size = None # è¨ˆç®—å¤±æ•—æ™‚ã¯Noneã«è¨­å®š


            self._update_status("LAFM analysis completed!", color="green")
            self._display_image(self.final_lafm_image, target='bottom')
            self.btn_save.setEnabled(True)
            
            if self.show_3d_check.isChecked() and self.viewer_3d_window is not None and self.params.get('mode') == '3D':
                self._update_status("Updating 3D viewer...", color="info")
                # â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘spacingã®è¨ˆç®—ã‚’å‰Šé™¤ã—ã€å‘¼ã³å‡ºã—ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã« â–¼â–¼â–¼
                self.viewer_3d_window.update_data(self.final_lafm_image)
            
        self._set_buttons_enabled(True, True, True)

    @QtCore.pyqtSlot()
    def _on_z_range_changed(self):
        self.z_min_spin.blockSignals(True)
        self.z_max_spin.blockSignals(True)
        z_min_val = self.z_min_spin.value()
        z_max_val = self.z_max_spin.value()
        if z_max_val < z_min_val:
            self.z_max_spin.setValue(z_min_val)
        self.z_max_spin.setMinimum(self.z_min_spin.value())
        self.z_min_spin.setMaximum(self.z_max_spin.value())
        self.z_min_spin.blockSignals(False)
        self.z_max_spin.blockSignals(False)

    @QtCore.pyqtSlot(int)
    def _on_filter_mode_changed(self, index):
        if index == 0:
            self.std_dev_label.setVisible(False)
            self.std_dev_factor_spin.setVisible(False)
            self.z_min_label.setText("Z_min (nm):")
        elif index == 1:
            self.std_dev_label.setVisible(True)
            self.std_dev_factor_spin.setVisible(True)
            self.z_min_label.setText("Z_min (nm, optional):")
    
    def _create_lafm_lut(self):
        color_stops = [(0, (0, 0, 0)), (85, (100, 0, 120)), (170, (255, 100, 0)), (220, (255, 255, 0)), (255, (255, 255, 255))]
        lut = np.zeros((256, 1, 3), dtype=np.uint8)
        for i in range(len(color_stops) - 1):
            start_index, start_color_rgb = color_stops[i]; end_index, end_color_rgb = color_stops[i+1]
            start_color_bgr = (start_color_rgb[2], start_color_rgb[1], start_color_rgb[0]); end_color_bgr = (end_color_rgb[2], end_color_rgb[1], end_color_rgb[0])
            for j in range(start_index, end_index + 1):
                ratio = (j - start_index) / (end_index - start_index)
                b = int(start_color_bgr[0]*(1.0-ratio) + end_color_bgr[0]*ratio); g = int(start_color_bgr[1]*(1.0-ratio) + end_color_bgr[1]*ratio); r = int(start_color_bgr[2]*(1.0-ratio) + end_color_bgr[2]*ratio)
                lut[j, 0] = [b, g, r]
        return lut

    
    def _execute_preprocessing1(self, image_stack, params, progress_signal=None, plot_signal=None):
        """ã€æœ€çµ‚FIX Dã€‘ç‰©ç†ã‚¯ãƒ­ãƒƒãƒ— + ãƒ”ã‚¯ã‚»ãƒ«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œã€ãƒ”ãƒ¼ã‚¯æ¤œå‡ºã¨å¯è¦–åŒ–ã‚’è¡Œã†å®Œå…¨ç‰ˆ"""
        
        try:
            if progress_signal:
                progress_signal.emit(5, "Initializing Preprocessing 1...")

            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨åˆæœŸè¨­å®š ---
            self.scale_info['offset_x'] = 0.0
            self.scale_info['offset_y'] = 0.0
            all_detections = []

            # --- ã‚¹ãƒ†ãƒƒãƒ—2: ç‰©ç†ã‚µã‚¤ã‚ºã«åŸºã¥ã„ã¦ç”»åƒã‚’æ­£æ–¹å½¢ã«ã‚¯ãƒ­ãƒƒãƒ— ---
            h_orig, w_orig, num_frames = image_stack.shape
            phys_side_length = min(gv.XScanSize, gv.YScanSize)
            nm_per_pixel_x = gv.XScanSize / w_orig
            nm_per_pixel_y = gv.YScanSize / h_orig

            crop_w_px = int(round(phys_side_length / nm_per_pixel_x))
            crop_h_px = int(round(phys_side_length / nm_per_pixel_y))

            # ã‚¯ãƒ­ãƒƒãƒ—ã‚µã‚¤ã‚ºãŒå…ƒç”»åƒã‚ˆã‚Šå¤§ãã„å ´åˆã®å‡¦ç†
            if crop_w_px > w_orig or crop_h_px > h_orig:
                # å…ƒç”»åƒã®ã‚µã‚¤ã‚ºã«åˆã‚ã›ã¦ã‚¯ãƒ­ãƒƒãƒ—ã‚µã‚¤ã‚ºã‚’èª¿æ•´
                crop_w_px = min(crop_w_px, w_orig)
                crop_h_px = min(crop_h_px, h_orig)
        

            start_x = max(0, (w_orig - crop_w_px) // 2)
            start_y = max(0, (h_orig - crop_h_px) // 2)

            # ã‚¯ãƒ­ãƒƒãƒ—ç¯„å›²ã®ãƒã‚§ãƒƒã‚¯
            if start_x + crop_w_px > w_orig or start_y + crop_h_px > h_orig:
                print(f"[ERROR] Invalid crop range: start_x={start_x}, start_y={start_y}, crop_w={crop_w_px}, crop_h={crop_h_px}, w_orig={w_orig}, h_orig={h_orig}")
                if hasattr(self, 'error'): self.error.emit("Invalid crop range detected.")
                return None, None

    
            image_stack_cropped = image_stack[start_y:start_y+crop_h_px, start_x:start_x+crop_w_px, :]
            
            # ã‚¯ãƒ­ãƒƒãƒ—å¾Œã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if image_stack_cropped.size == 0:
                print(f"[ERROR] Cropped image is empty")
                if hasattr(self, 'error'): self.error.emit("Cropped image is empty.")
                return None, None

            # --- ã‚¹ãƒ†ãƒƒãƒ—3: ãƒ”ã‚¯ã‚»ãƒ«æ•°ãŒæ­£æ–¹å½¢ã«ãªã‚‹ã‚ˆã†ã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° ---
            if progress_signal:
                progress_signal.emit(10, "Resampling to square pixels...")

            target_pixel_size = max(crop_w_px, crop_h_px)
    
            
            resampled_stack = np.zeros((target_pixel_size, target_pixel_size, num_frames), dtype=np.float32)

            for i in range(num_frames):
                frame_cropped = image_stack_cropped[:, :, i]
                if frame_cropped.size == 0:
                    print(f"[ERROR] Frame {i} is empty after cropping")
                    continue
                    
                try:
                    resampled_stack[:, :, i] = cv2.resize(
                        frame_cropped, 
                        (target_pixel_size, target_pixel_size), 
                        interpolation=cv2.INTER_CUBIC
                    )
                except Exception as e:
                    print(f"[ERROR] Failed to resize frame {i}: {e}")
                    if hasattr(self, 'error'): self.error.emit(f"Failed to resize frame {i}: {e}")
                    return None, None

            # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å¾Œã®ãƒã‚§ãƒƒã‚¯
            if np.all(resampled_stack == 0):
                print(f"[ERROR] All frames are zero after resampling")
                if hasattr(self, 'error'): self.error.emit("All frames are zero after resampling.")
                return None, None
            
    

            # --- ã‚¹ãƒ†ãƒƒãƒ—4: ã‚¹ã‚±ãƒ¼ãƒ«æƒ…å ±ã‚’æ›´æ–° ---
            new_nm_per_pixel = phys_side_length / target_pixel_size
            self.scale_info['dx'] = new_nm_per_pixel
            self.scale_info['dy'] = new_nm_per_pixel
            self.scale_info['offset_x'] += start_x * nm_per_pixel_x
            self.scale_info['offset_y'] += start_y * nm_per_pixel_y

             # --- ã‚¹ãƒ†ãƒƒãƒ—B: ãƒ‰ãƒªãƒ•ãƒˆè£œæ­£ ---
            corrected_stack = resampled_stack
            if params.get('drift_correction', False):
                if progress_signal:
                    progress_signal.emit(10, "Applying drift correction...")
                
                try:
                    # averagingãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰æ–°ã—ã„ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
                    from averaging import calculate_drift_matrices
                    
                    is_rot = "Feature-based" in params['drift_algorithm']
                    conf_thresh = params['drift_threshold']
                    
                    # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦å¤‰æ›è¡Œåˆ—ã‚’è¨ˆç®—
                    matrices, confidences = calculate_drift_matrices(
                        resampled_stack, 
                        is_rotation_enabled=is_rot
                    )
                    
                    # ä¿¡é ¼åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    good_indices = np.where(confidences > conf_thresh)[0]
                    
                    if len(good_indices) < 2:
                        print("Warning: Not enough stable frames. Skipping drift correction.")
                    else:
                        stack_to_correct = resampled_stack[:, :, good_indices]
                        matrices_to_apply = matrices[good_indices]
                        
                        if progress_signal:
                            progress_signal.emit(15, f"Applying corrections to {len(good_indices)} frames...")
                        
                        # å¤‰æ›è¡Œåˆ—ã‚’é©ç”¨
                        h, w = stack_to_correct.shape[:2]
                        corrected_frames = []
                        # np.rollaxisã‚’ä½¿ã£ã¦æ­£ã—ããƒ•ãƒ¬ãƒ¼ãƒ ã‚’ãƒ«ãƒ¼ãƒ—å‡¦ç†
                        for i, (img, M) in enumerate(zip(np.rollaxis(stack_to_correct, 2), matrices_to_apply)):
                            border_val = float(np.median(img))
                            corrected_frame = cv2.warpAffine(
                                img.astype(np.float32), M, (w, h), 
                                borderValue=border_val
                            )
                            corrected_frames.append(corrected_frame)
                        
                        corrected_stack = np.stack(corrected_frames, axis=2)
                        
                        excluded_frames = resampled_stack.shape[2] - len(good_indices)
                        if excluded_frames > 0 and progress_signal:
                            progress_signal.emit(18, f"Drift correction: {excluded_frames} frames excluded")
                            
                except Exception as e:
                    if progress_signal:
                        progress_signal.emit(18, f"Drift correction failed: {str(e)[:50]}...")
                    print(f"Drift correction failed: {e}")
                    # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å…ƒã®ã‚¹ã‚¿ãƒƒã‚¯ã‚’ä½¿ç”¨
                    corrected_stack = resampled_stack

    

            # --- ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ”ãƒ¼ã‚¯æ¤œå‡ºå‡¦ç† ---
            height, width = target_pixel_size, target_pixel_size
            



            num_corrected_frames = corrected_stack.shape[2]
            all_detections = [] # æ¤œå‡ºçµæœã‚’åˆæœŸåŒ–

            for i in range(num_frames):
                if progress_signal:
                    progress_signal.emit(int(20 + 80 * i / num_corrected_frames), f"Detecting peaks in frame {i+1}/{num_corrected_frames}")

                frame_abs = corrected_stack[:, :, i]
                
                # ãƒ•ãƒ¬ãƒ¼ãƒ ã®çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯
                if frame_abs.size == 0 or np.all(frame_abs == 0):
                    print(f"[WARNING] Frame {i} is empty or all zero")
                    continue
                

                    
                frame_rel = frame_abs - np.min(frame_abs)
                
                # A, B, C: é«˜ã•ã€å±€æ‰€æœ€å¤§å€¤ã€ç©ºé–“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                threshold = -np.inf
                if params['filter_mode'] == 'Statistics (Mean + N x Std Dev)' and np.std(frame_rel) > 1e-9:
                    threshold = np.mean(frame_rel) + (params['std_dev_factor'] * np.std(frame_rel))
    
                
                height_mask = (frame_rel >= threshold) & (frame_abs >= params['z_min']) & (frame_abs <= params['z_max'])

                
                # å„æ¡ä»¶ã®è©³ç´°ã‚’å‡ºåŠ›ï¼ˆæœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
                if i == 0:
                    threshold_mask = (frame_rel >= threshold)
                    z_min_mask = (frame_abs >= params['z_min'])
                    z_max_mask = (frame_abs <= params['z_max'])
    


                footprint = np.ones((3, 3)) if params['connectivity'] == 8 else np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
                maxima_mask = (frame_abs == maximum_filter(frame_abs, footprint=footprint, mode='constant', cval=0.0))


                center_x, center_y = width / 2, height / 2
                crop_radius_sq = (min(width, height) / 2 * params['crop_ratio'])**2
                y_coords, x_coords = np.ogrid[:height, :width]
                spatial_mask = ((x_coords - center_x)**2 + (y_coords - center_y)**2) < crop_radius_sq

                
                # D: æœ€çµ‚çš„ãªãƒ”ãƒ¼ã‚¯ãƒã‚¹ã‚¯ã¨åº§æ¨™
                final_peaks_mask = height_mask & maxima_mask & spatial_mask
                peak_coords_y, peak_coords_x = np.where(final_peaks_mask)
                final_maxima_coords_int = list(zip(peak_coords_y, peak_coords_x))
                

                
                # æœ€åˆã®ãƒ•ãƒ¬ãƒ¼ãƒ ã§ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’å‡ºåŠ›
                if i == 0:
                    pass    


                # E: ã‚µãƒ–ãƒ”ã‚¯ã‚»ãƒ«å‡¦ç†ã¾ãŸã¯æ•´æ•°åº§æ¨™ã®æ ¼ç´
                if params['subpixel_on']:
                    refined_detections_for_frame = []
                    radius, scale = 2, params['subpixel_scale']
                    for y_int, x_int in final_maxima_coords_int:
                        y_start, y_end = max(0, y_int - radius), min(height, y_int + radius + 1)
                        x_start, x_end = max(0, x_int - radius), min(width, x_int + radius + 1)
                        roi = frame_abs[y_start:y_end, x_start:x_end]
                        if roi.size == 0: continue
                        zoomed_roi = zoom(roi, scale, order=3)
                        max_coords_local = np.unravel_index(np.argmax(zoomed_roi), zoomed_roi.shape)
                        sub_y = y_start + max_coords_local[0] / scale
                        sub_x = x_start + max_coords_local[1] / scale
                        all_detections.append([sub_y, sub_x, frame_abs[y_int, x_int], i, 0.0, 0.0, 0.0, 1.0])
                        refined_detections_for_frame.append((sub_y, sub_x))
                    
                    if plot_signal:
                        display_frame = cv2.normalize(frame_abs, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                        plot_img = cv2.cvtColor(display_frame, cv2.COLOR_GRAY2BGR)
                        for sub_y, sub_x in refined_detections_for_frame:
                            cv2.circle(plot_img, (int(round(sub_x)), int(round(sub_y))), 1, (0, 255, 255), -1)
                        plot_signal.emit(plot_img, 'top')
                        if params['vis_delay_spin'] > 0: time.sleep(params['vis_delay_spin'] / 1000.0)
                else: # ã‚µãƒ–ãƒ”ã‚¯ã‚»ãƒ«OFFã®å ´åˆ
                    for y, x in final_maxima_coords_int:
                        all_detections.append([float(y), float(x), frame_abs[y, x], i, 0.0, 0.0, 0.0, 1.0])
                    
                    if plot_signal:
                        display_frame = cv2.normalize(frame_abs, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)
                        plot_img = cv2.cvtColor(display_frame, cv2.COLOR_GRAY2BGR)
                        for y_coord, x_coord in final_maxima_coords_int:
                            cv2.circle(plot_img, (x_coord, y_coord), 1, (0, 0, 255), -1)
                        plot_signal.emit(plot_img, 'top')
                        if params['vis_delay_spin'] > 0: time.sleep(params['vis_delay_spin'] / 1000.0)

            # --- ã‚¹ãƒ†ãƒƒãƒ—6: æœ€çµ‚å‡¦ç† ---
            detections = np.array(all_detections)
    
            
            if len(detections) == 0:
                print(f"[ERROR] No peaks detected in any frame")
                if hasattr(self, 'error'): self.error.emit("No peaks detected.")
                return None, None # 2ã¤ã®å€¤ã‚’è¿”ã™
            
            if progress_signal: progress_signal.emit(100, "Preprocessing 1 Finished.")
    
            return detections, resampled_stack

        except Exception as e:
            import traceback
            error_msg = f"Error in Preprocessing 1: {e}\n\n{traceback.format_exc()}"
            if hasattr(self, 'error'): self.error.emit(error_msg)
            else: print(error_msg)
            return None, None # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚2ã¤ã®å€¤ã‚’è¿”ã™

    def _execute_preprocessing2(self, detection_summary, processed_image_stack, params, progress_signal=None, plot_signal=None):
        """ã€å®Œæˆç‰ˆã€‘æ¸¡ã•ã‚ŒãŸç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‚’åŸºæº–ã«å†æ§‹æˆã™ã‚‹"""
        
        # --- ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã‚°ãƒªãƒƒãƒ‰ã‚µã‚¤ã‚ºã®æº–å‚™ ---
        if progress_signal:
            progress_signal.emit(5, "Initializing reconstruction grid...")

        # æ¸¡ã•ã‚ŒãŸç”»åƒã‚¹ã‚¿ãƒƒã‚¯(Preprocessing 1ã§å‡¦ç†æ¸ˆã¿)ã‹ã‚‰æƒ…å ±ã‚’å–å¾—
        h_proc, w_proc, total_frames = processed_image_stack.shape
        is_3d_mode = (params['mode'] == '3D')

        # å†æ§‹æˆå¾Œã®ç‰©ç†ã‚µã‚¤ã‚ºã‚’è¨ˆç®— (scale_infoã¯æ›´æ–°æ¸ˆã¿)
        scan_size_x = w_proc * self.scale_info['dx']
        scan_size_y = h_proc * self.scale_info['dy']

        # æ–°ã—ã„ã‚°ãƒªãƒƒãƒ‰ã®ãƒ”ã‚¯ã‚»ãƒ«æ•°ã‚’è¨ˆç®—
        if params['subpixel_on']:
            xy_res = params['subpixel_xy_res']
            reconst_w = int(round(scan_size_x / xy_res)) if xy_res > 0 else w_proc
            reconst_h = int(round(scan_size_y / xy_res)) if xy_res > 0 else h_proc
        else:
            reconst_w, reconst_h = w_proc, h_proc

        reconst_dx = scan_size_x / reconst_w
        reconst_dy = scan_size_y / reconst_h

        # --- ã‚¹ãƒ†ãƒƒãƒ—2: å†æ§‹æˆç”¨ã‚°ãƒªãƒƒãƒ‰ã®ä½œæˆ ---
        reconstruction_grid = None
        reconstruction_image = None # 2Dãƒ¢ãƒ¼ãƒ‰ã§ä½¿ã†ã€å¼·åº¦é‡ã¿ä»˜ã‘ç”¨ã®ç”»åƒ

        if is_3d_mode:
            # 3Dãƒ¢ãƒ¼ãƒ‰ï¼šãƒœã‚¯ã‚»ãƒ«ã‚°ãƒªãƒƒãƒ‰ã‚’ä½œæˆ
            z_res = params['subpixel_z_res']
            z_values = detection_summary[:, 2]
            z_min, z_max = np.min(z_values), np.max(z_values)
            
            num_z_bins = 1
            if z_res > 0 and (z_max > z_min):
                num_z_bins = int(np.ceil((z_max - z_min) / z_res))
            
            reconstruction_grid = np.zeros((reconst_h, reconst_w, num_z_bins))
        else: # 2Dãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ
            reconstruction_grid = np.zeros((reconst_h, reconst_w, total_frames))
            # å¼·åº¦è¨ˆç®—ç”¨ã«ã€å‡¦ç†æ¸ˆã¿ã®ç”»åƒã‚¹ã‚¿ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä»£å…¥ã™ã‚‹ (forãƒ«ãƒ¼ãƒ—ã¯ä¸è¦)
            reconstruction_image = np.zeros((reconst_h, reconst_w, total_frames))

             # ãƒ«ãƒ¼ãƒ—ã‚’å›ã—ã¦ã€å„ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æ–°ã—ã„è§£åƒåº¦ã«ãƒªã‚µã‚¤ã‚ºã™ã‚‹
            for i in range(total_frames):
                if progress_signal:
                    progress_signal.emit(int(10 + 20 * i / total_frames), f"Upscaling original image {i+1}")
                frame_to_resize = processed_image_stack[:, :, i]
                reconstruction_image[:, :, i] = cv2.resize(
                    frame_to_resize, (reconst_w, reconst_h), interpolation=cv2.INTER_CUBIC)

 

        # --- ã‚¹ãƒ†ãƒƒãƒ—3: å…¨ã¦ã®æ¤œå‡ºç‚¹ã‚’æ–°ã—ã„ã‚°ãƒªãƒƒãƒ‰ã«ãƒãƒƒãƒ”ãƒ³ã‚° ---
        num_detections = len(detection_summary)
        for idx, detection in enumerate(detection_summary):
            if progress_signal and idx % 1000 == 0:
                progress_signal.emit(int(30 + 50 * idx / num_detections), f"Mapping detection {idx+1}")

            y_orig_px, x_orig_px, z_abs_nm, frame_idx = detection[0], detection[1], detection[2], int(detection[3])

            x_nm = x_orig_px * self.scale_info['dx']
            y_nm = y_orig_px * self.scale_info['dy']

            pixel_x = int(round(x_nm / reconst_dx))
            pixel_y = int(round(y_nm / reconst_dy))

            if not (0 <= pixel_y < reconst_h and 0 <= pixel_x < reconst_w):
                continue

            if is_3d_mode:
                voxel_z = 0
                if z_res > 0 and (z_max > z_min):
                    voxel_z = int((z_abs_nm - z_min) / z_res)
                if 0 <= voxel_z < num_z_bins:
                    reconstruction_grid[pixel_y, pixel_x, voxel_z] += 1
            else: # 2Dãƒ¢ãƒ¼ãƒ‰
                if 0 <= frame_idx < total_frames:
                    reconstruction_grid[pixel_y, pixel_x, frame_idx] = 1

        # --- ã‚¹ãƒ†ãƒƒãƒ—4: å¯¾ç§°åŒ–å‡¦ç† (ã‚ªãƒ—ã‚·ãƒ§ãƒ³) ---
        if params['sym_on'] and params['sym_on_prep2'] and params['sym_order'] > 1:
            if progress_signal: progress_signal.emit(85, "Applying symmetry...")
            
            order = params['sym_order']
            avg_reconstruction = np.zeros_like(reconstruction_grid)
            num_slices = reconstruction_grid.shape[2]
            for i in range(num_slices):
                original_slice = reconstruction_grid[:, :, i]
                if not np.any(original_slice):
                    avg_reconstruction[:, :, i] = original_slice
                    continue
                summed_slice = np.zeros_like(original_slice, dtype=np.float32)
                for j in range(order):
                    angle = j * 360.0 / order
                    rotated = rotate(original_slice, angle, reshape=False, order=1, mode='constant', cval=0.0)
                    summed_slice += rotated
                avg_reconstruction[:, :, i] = summed_slice / order
            reconstruction_grid = avg_reconstruction

        # --- ã‚¹ãƒ†ãƒƒãƒ—5: å¯è¦–åŒ–ã¨çµ‚äº†å‡¦ç† ---
        if plot_signal:
            display_img = np.max(reconstruction_grid, axis=2) if is_3d_mode else np.sum(reconstruction_grid, axis=2)
            plot_signal.emit(display_img, 'bottom')
            if params.get('vis_delay_spin', 0) > 0: time.sleep(params['vis_delay_spin'] / 1000.0)

        if progress_signal: progress_signal.emit(100, "Preprocessing 2 Finished.")
            
        reconst_scan_size = {'x': scan_size_x, 'y': scan_size_y}
        return reconstruction_grid, reconstruction_image, reconst_scan_size

    def _execute_make_lafm_image(self, reconstruction, reconstruction_image, params, progress_signal=None, plot_signal=None):
        if params['mode'] == '2D':
            if progress_signal: progress_signal.emit(10, "Constructing 2D LAFM image...")
            num_frames = reconstruction.shape[2]
            final_image = np.zeros(reconstruction.shape[:2], dtype=np.float32)
            sigma = params['blur_sigma_xy']
            
            for i in range(num_frames):
                if progress_signal:
                    progress_signal.emit(int(10 + 80 * i / num_frames), f"Processing frame {i+1}/{num_frames}")
                
                probability_wave = reconstruction[:, :, i]
                
                if np.any(probability_wave):
                    blurred_prob = gaussian_filter(probability_wave, sigma=sigma)
                    if plot_signal:
                        display_prob = blurred_prob / np.max(blurred_prob) if np.max(blurred_prob) > 0 else blurred_prob
                        plot_signal.emit(display_prob, 'top')

                    intensity_frame = reconstruction_image[:, :, i]
                    intensity_frame_norm = intensity_frame - np.min(intensity_frame)
                    final_image += (blurred_prob * intensity_frame_norm)
                
                if plot_signal and (i % 5 == 0 or i == num_frames - 1):
                    processed_frames = i + 1
                    display_avg_image = final_image / processed_frames if processed_frames > 0 else final_image
                    plot_signal.emit(display_avg_image, 'bottom')
            
            if num_frames > 0:
                final_image /= num_frames
            
        else: # 3D Mode
            if progress_signal: progress_signal.emit(10, "Applying 3D Gaussian Blur...")
            sigma_xy = params['blur_sigma_xy']
            sigma_z = params['blur_sigma_z']
            final_image = gaussian_filter(reconstruction.astype(np.float32), sigma=(sigma_xy, sigma_xy, sigma_z))
            if plot_signal: plot_signal.emit(np.max(final_image, axis=2), 'bottom')
            if progress_signal: progress_signal.emit(80, "Blurring finished.")
        
        if params['sym_on'] and params['sym_on_final'] and params['sym_order'] > 1:
            if progress_signal: progress_signal.emit(90, "Applying post-symmetry...")
            order = params['sym_order']
            angle_step = 360.0 / order
            interpolation_order = 0
            
            if len(final_image.shape) == 2:
                summed_slice = np.zeros_like(final_image, dtype=np.float32)
                for j in range(order):
                    rotated = rotate(final_image, j * angle_step, reshape=False, order=interpolation_order)
                    summed_slice += rotated
                final_image = summed_slice / order
            else: # 3D
                avg_reconstruction = np.zeros_like(final_image)
                num_slices = final_image.shape[2]
                for k in range(num_slices):
                    original_slice = final_image[:, :, k]
                    summed_slice = np.zeros_like(original_slice, dtype=np.float32)
                    for j in range(order):
                        rotated = rotate(original_slice, j * angle_step, reshape=False, order=interpolation_order)
                        summed_slice += rotated
                    avg_reconstruction[:, :, k] = summed_slice / order
                    if plot_signal and (k % 5 == 0 or k == num_slices - 1):
                        plot_signal.emit(np.max(avg_reconstruction, axis=2), 'bottom')
                        if params.get('vis_delay_spin', 0) > 0: time.sleep(params['vis_delay_spin'] / 1000.0)
                final_image = avg_reconstruction
        
        if progress_signal: progress_signal.emit(100, "Final image created.")
        
        # --- â–¼â–¼â–¼ æ­£ã—ã„æˆ»ã‚Šå€¤ â–¼â–¼â–¼ ---
        return final_image
    
    @QtCore.pyqtSlot(int)
    def _on_mode_changed(self, index):
        """Modeã‚³ãƒ³ãƒœãƒœãƒƒã‚¯ã‚¹ã®å¤‰æ›´ã«å¿œã˜ã¦UIã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹"""
        is_3d_mode = (self.mode_combo.currentText() == "3D")
        self.show_3d_check.setVisible(is_3d_mode)
        # 2Dãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆãŸã‚‰ã€3Dè¡¨ç¤ºã¯ã‚ªãƒ•ã«ã™ã‚‹
        if not is_3d_mode and self.show_3d_check.isChecked():
            self.show_3d_check.setChecked(False)

    @QtCore.pyqtSlot(bool)
    def _handle_3d_display_toggle(self, checked):
        """ã€Œ3D Displayã€ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã«å¿œã˜ã¦ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’é–‹é–‰ã™ã‚‹"""
        if not PYVISTA_AVAILABLE:
            self.show_3d_check.setChecked(False)
            detail = f"\n\nè©³ç´°: {PV_IMPORT_ERROR}" if PV_IMPORT_ERROR else ""
            _frozen = getattr(sys, "frozen", False)
            if _frozen:
                msg = (
                    "3D Display requires PyVista, PyVistaQt, and VTK.\n"
                    "3Dè¡¨ç¤ºã«ã¯ PyVistaã€PyVistaQtã€VTK ãŒå¿…è¦ã§ã™ã€‚\n\n"
                    "These modules are not installed. They are not bundled with this installation.\n"
                    "ã“ã‚Œã‚‰ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã“ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã«å«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚" + detail
                )
            else:
                msg = (
                    "3D Display requires PyVista, PyVistaQt, and VTK.\n"
                    "3Dè¡¨ç¤ºã«ã¯ PyVistaã€PyVistaQtã€VTK ãŒå¿…è¦ã§ã™ã€‚\n\n"
                    "Install with: pip install pyvista pyvistaqt\n"
                    "(VTK is installed automatically as a dependency of PyVista.)\n"
                    "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: pip install pyvista pyvistaqt\n"
                    "ï¼ˆVTK ã¯ PyVista ã®ä¾å­˜é–¢ä¿‚ã¨ã—ã¦è‡ªå‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¾ã™ã€‚ï¼‰\n\n"
                    "After installing, try enabling 3D Display again.\n"
                    "ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å¾Œã€å†åº¦ 3D Display ã‚’æœ‰åŠ¹ã«ã—ã¦ãã ã•ã„ã€‚" + detail
                )
            QtWidgets.QMessageBox.critical(
                self, "Library Not Found / ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", msg
            )
            return

        if checked:
            if self.final_lafm_image is None or self.params.get('mode') != '3D':
                self.show_3d_check.setChecked(False)
                QtWidgets.QMessageBox.warning(self, "No 3D Data", "è¡¨ç¤ºã™ã‚‹3D LAFMãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚\nå…ˆã«3Dãƒ¢ãƒ¼ãƒ‰ã§ã€ŒMake LAFM Imageã€ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
                return

            try:
                if self.viewer_3d_window is None:
                    self.viewer_3d_window = Voxel3DViewer(parent=None) # è¦ªã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚’æ¸¡ã™
                    # ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ãŒé–‰ã˜ã‚‰ã‚ŒãŸã‚‰ã€ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã—ã€è¨­å®šã‚’ä¿å­˜ã™ã‚‹
                    self.viewer_3d_window.was_closed.connect(self._on_3d_viewer_closed)

                # â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘spacingã®è¨ˆç®—ã‚’å‰Šé™¤ã—ã€å‘¼ã³å‡ºã—ã‚’ã‚·ãƒ³ãƒ—ãƒ«ã« â–¼â–¼â–¼
                self.viewer_3d_window.update_data(self.final_lafm_image)
                self.viewer_3d_window.show()
                self.viewer_3d_window.raise_()
            except Exception as e:
                print(f"[ERROR] Failed to create 3D viewer: {e}")
                import traceback
                traceback.print_exc()
                self.show_3d_check.setChecked(False)
                QtWidgets.QMessageBox.critical(self, "3D Viewer Error", f"3Dãƒ“ãƒ¥ãƒ¼ã‚¢ã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\nã‚¨ãƒ©ãƒ¼: {e}")
        else:
            if self.viewer_3d_window is not None:
                try:
                    self.viewer_3d_window.close()
                except Exception as e:
                    print(f"[ERROR] Failed to close 3D viewer: {e}")
                self.viewer_3d_window = None
    
    def _on_3d_viewer_closed(self):
        """3Dãƒ“ãƒ¥ãƒ¼ã‚¢ãŒé–‰ã˜ã‚‰ã‚ŒãŸã¨ãã«å‘¼ã³å‡ºã•ã‚Œã‚‹ã‚¹ãƒ­ãƒƒãƒˆ"""
        if self.viewer_3d_window:
            # 1. ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™
            self.show_3d_check.setChecked(False)
            
            # 2. ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦è¨­å®šã‚’ä¿å­˜
            try:
                if not hasattr(gv, 'windowSettings'): gv.windowSettings = {}
                gv.windowSettings[self.viewer_3d_window.__class__.__name__] = {
                    'visible': False
                }
                # ãƒ¡ã‚¤ãƒ³ã®ä¿å­˜æ©Ÿèƒ½ã‚’å‘¼ã³å‡ºã™
                if self.main_window and hasattr(self.main_window, 'saveAllInitialParams'):
                    self.main_window.saveAllInitialParams()
            except Exception as e:
                print(f"Error saving 3D viewer settings: {e}")
            
            # 3. å‚ç…§ã‚’ã‚¯ãƒªã‚¢
            self.viewer_3d_window = None

    def _save_lafm_as_asd(self, save_path, comment, image_data):
        """LAFMã®2Dç”»åƒã‚’ã€è¼åº¦ã‚’æ­£ã—ãæ­£è¦åŒ–ã—ã¦ASDå½¢å¼ã§ä¿å­˜ã™ã‚‹ï¼ˆå …ç‰¢ç‰ˆï¼‰"""
        try:
            import struct
            import datetime

            # --- ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®æº–å‚™ ---
            y_pixels, x_pixels = image_data.shape

            save_x_scan_size = int(self.lafm_image_scan_size['x'])
            save_y_scan_size = int(self.lafm_image_scan_size['y'])

            
            # å¿…é ˆãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±ã®å­˜åœ¨ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä½¿ç”¨
            required_params = {
                'FileType': 1, 'FrameHeaderSize': 64, 'TextEncoding': 0, 'DataType1ch': 1, 
                'DataType2ch': 0, 'ScanDirection': 0, 'ScanTryNum': 1, 'AveFlag': 0, 'AveNum': 1,
                'XRound': 0, 'YRound': 0, 'FrameTime': 1000.0, 'Sensitivity': 1.0, 'PhaseSens': 1.0, 
                'MachineNo': 0, 'ADRange': 0, 'ADResolution': 0, 'PiezoConstX': 1.0,
                'PiezoConstY': 1.0, 'PiezoConstZ': 1.0, 'DriverGainZ': 1.0
            }
            header_values = {}
            for param, default in required_params.items():
                header_values[param] = getattr(gv, param, default)

        
            max_scan_size_x = getattr(gv, 'MaxScanSizeX', float(save_x_scan_size))
            max_scan_size_y = getattr(gv, 'MaxScanSizeY', float(save_y_scan_size))

            # æ–‡å­—åˆ—æƒ…å ±ã®ãƒã‚§ãƒƒã‚¯
            if not hasattr(gv, 'OpeName') or gv.OpeName is None:
                print("[WARNING] SaveASD: gv.OpeName not available, using default: 'pyNuD'")
                ope_name = "pyNuD"
            else:
                ope_name = gv.OpeName

            # UTF-8ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
            ope_name_bytes = ope_name.encode('utf-8')
            comment_bytes = comment.encode('utf-8')
            ope_name_size = len(ope_name_bytes)
            comment_size_for_save = len(comment_bytes)

            # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
            original_file_header_size = getattr(gv, 'FileHeaderSize', 0)
            original_comment_size = getattr(gv, 'CommentSize', 0)
            
            if original_file_header_size > 0 and original_comment_size > 0:
                size = original_file_header_size - original_comment_size
                file_header_size_for_save = size + comment_size_for_save
            else:
                fixed_header_size = 37 * 4 + 1  # 37å€‹ã®4byteå€¤ + AveFlag(1byte)
                file_header_size_for_save = fixed_header_size + ope_name_size + comment_size_for_save
            
            # æ™‚åˆ»æƒ…å ±
            time_params = ['Year', 'Month', 'Day', 'Hour', 'Minute', 'Second']
            time_values = {}
            missing_time_params = []

            for param in time_params:
                if hasattr(gv, param) and getattr(gv, param) is not None:
                    time_values[param] = getattr(gv, param)
                else:
                    missing_time_params.append(param)
        
            # æ™‚åˆ»æƒ…å ±ãŒä¸å®Œå…¨ãªå ´åˆã®å‡¦ç†
            if missing_time_params:
                print(f"[WARNING] SaveASD: Missing time parameters: {missing_time_params}, using current time")
                now = datetime.datetime.now()
                time_values['Year'] = time_values.get('Year', now.year)
                time_values['Month'] = time_values.get('Month', now.month)
                time_values['Day'] = time_values.get('Day', now.day)
                time_values['Hour'] = time_values.get('Hour', now.hour)
                time_values['Minute'] = time_values.get('Minute', now.minute)
                time_values['Second'] = time_values.get('Second', now.second)
            
            

            # --- ã‚¹ãƒ†ãƒƒãƒ—2: ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®æ›¸ãè¾¼ã¿ ---
            with open(save_path, 'wb') as f:
                # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ˜ãƒƒãƒ€ãƒ¼
                f.write(struct.pack('<i', header_values['FileType'])); f.write(struct.pack('<i', file_header_size_for_save)); f.write(struct.pack('<i', header_values['FrameHeaderSize']))
                f.write(struct.pack('<i', header_values['TextEncoding'])); f.write(struct.pack('<i', ope_name_size)); f.write(struct.pack('<i', comment_size_for_save))
                f.write(struct.pack('<i', header_values['DataType1ch'])); f.write(struct.pack('<i', header_values['DataType2ch']))
                f.write(struct.pack('<i', 1)); f.write(struct.pack('<i', 1)) # 1ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿
                f.write(struct.pack('<i', header_values['ScanDirection'])); f.write(struct.pack('<i', header_values['ScanTryNum']))
                f.write(struct.pack('<i', x_pixels)); f.write(struct.pack('<i', y_pixels))
                f.write(struct.pack('<i', save_x_scan_size)); f.write(struct.pack('<i', save_y_scan_size))
                f.write(struct.pack('<B', header_values['AveFlag'])); f.write(struct.pack('<i', header_values['AveNum']))
                f.write(struct.pack('<i', time_values['Year'])); f.write(struct.pack('<i', time_values['Month'])); f.write(struct.pack('<i', time_values['Day']))
                f.write(struct.pack('<i', time_values['Hour'])); f.write(struct.pack('<i', time_values['Minute'])); f.write(struct.pack('<i', time_values['Second']))
                f.write(struct.pack('<i', header_values['XRound'])); f.write(struct.pack('<i', header_values['YRound']))
                f.write(struct.pack('<f', header_values['FrameTime'])); f.write(struct.pack('<f', header_values['Sensitivity'])); f.write(struct.pack('<f', header_values['PhaseSens']))
                f.write(struct.pack('<iiii', 0, 0, 0, 0))
                f.write(struct.pack('<i', header_values['MachineNo'])); f.write(struct.pack('<i', header_values['ADRange'])); f.write(struct.pack('<i', header_values['ADResolution']))
                f.write(struct.pack('<f', max_scan_size_x)); f.write(struct.pack('<f', max_scan_size_y))
                f.write(struct.pack('<f', header_values['PiezoConstX'])); f.write(struct.pack('<f', header_values['PiezoConstY']))
                f.write(struct.pack('<f', header_values['PiezoConstZ'])); f.write(struct.pack('<f', header_values['DriverGainZ']))
                f.write(ope_name_bytes); f.write(comment_bytes)

                # --- â–¼â–¼â–¼ã€é‡è¦ä¿®æ­£ç‚¹ã€‘ç”»åƒãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›ã¨æ›¸ãè¾¼ã¿ â–¼â–¼â–¼ ---
                # Yè»¸åè»¢ã‚’å‰Šé™¤ã—ã¦ã€å…ƒã®å‘ãã®ã¾ã¾ä¿å­˜
                # 2. LAFMè§£æã¯å‡¹å‡¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ãªã®ã§ã€nm â†’ uint16ã®å¤‰æ›ã®ã¿
                converted_data = (5.0 - image_data / header_values['PiezoConstZ'] / header_values['DriverGainZ']) * 4096.0 / 10.0
                
                # 3. ãƒ‡ãƒ¼ã‚¿ç¯„å›²ã‚’0-65535ã«æ­£è¦åŒ–
                data_min = np.min(converted_data)
                data_max = np.max(converted_data)
                
                if data_max > data_min:
                    # ã‚ªãƒ•ã‚»ãƒƒãƒˆã‚’é©ç”¨ã—ã¦è² ã®å€¤ã‚’é¿ã‘ã‚‹
                    offset = max(0, -data_min)
                    shifted_data = converted_data + offset
                    
                    # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ã‚’é©ç”¨ã—ã¦uint16ã®ç¯„å›²ã«åã‚ã‚‹
                    scale_factor = 65535.0 / (data_max + offset)
                    scaled_data = shifted_data * scale_factor
                    
                    # æœ€çµ‚çš„ãªuint16å¤‰æ›ï¼ˆä¸¸ã‚èª¤å·®ã‚’æœ€å°åŒ–ï¼‰
                    normalized_data = np.round(np.clip(scaled_data, 0, 65535)).astype(np.uint16)
                else:
                    normalized_data = np.zeros_like(converted_data, dtype=np.uint16)

                min_data_int = int(np.min(normalized_data))
                max_data_int = int(np.max(normalized_data))
                # ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ˜ãƒƒãƒ€ãƒ¼
                f.seek(file_header_size_for_save)
                f.write(struct.pack('<I', 0)); f.write(struct.pack('<H', max_data_int)); f.write(struct.pack('<H', min_data_int))
                f.write(struct.pack('<h', 0)); f.write(struct.pack('<h', 0)); f.write(struct.pack('<f', 0.0)); f.write(struct.pack('<f', 0.0))
                f.write(struct.pack('<B', 0)); f.write(struct.pack('<B', 0)); f.write(struct.pack('<h', 0)); f.write(struct.pack('<i', 0)); f.write(struct.pack('<i', 0))

                # æ­£è¦åŒ–ã•ã‚ŒãŸç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æ›¸ãè¾¼ã¿
                f.write(normalized_data.tobytes())
            
            return True

        except Exception as e:
            print(f"[ERROR] _save_lafm_as_asd failed: {e}")
            import traceback
            traceback.print_exc()
            return False


def create_plugin(main_window):
    """ãƒ—ãƒ©ã‚°ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆã€‚pyNuD ã® Plugin ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ã€‚"""
    return LAFMPanelWindow(main_window)


__all__ = ["PLUGIN_NAME", "create_plugin", "LAFMPanelWindow"]
